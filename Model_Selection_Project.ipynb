{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link\n",
    "https://github.com/fivethirtyeight/data/tree/master/candy-power-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose this dataset because I enjoy candy and have wondered what makes certain candy more likeable. I looked at the data and it seemed like there wasn't a lot that needed to be done to it clean up wise so that was good. In addition questions that usually don't have a numerical answer were quantified with 0's for nos and 1's for yes, making it easier for me to look at. The data set was also not too big, so I could work on it without struggling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import hashlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = pandas.read_csv(\"candy-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset that looks at how certain candy can be liked and others disliked. The goal is to estimate whether a candy bar will be more likely or less likely to be chosen depending on which features it carries. For example 66% of a sample population like 100 grand candy bar while Almond Joy is at 50% of the same population. Some features include whether the candy contains chocolate, is it fruit flavored, does the candy contain caramel, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions of Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 13)\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Almond Joy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.767</td>\n",
       "      <td>50.347546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baby Ruth</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.767</td>\n",
       "      <td>56.914547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boston Baked Beans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.511</td>\n",
       "      <td>23.417824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Candy Corn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.325</td>\n",
       "      <td>38.010963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Caramel Apple Pops</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.325</td>\n",
       "      <td>34.517681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Charleston Chew</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>38.975037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chewey Lemonhead Fruit Mix</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.511</td>\n",
       "      <td>36.017628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chiclets</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.325</td>\n",
       "      <td>24.524988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dots</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.511</td>\n",
       "      <td>42.272076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dum Dums</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.034</td>\n",
       "      <td>39.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fruit Chews</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.034</td>\n",
       "      <td>43.088924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fun Dip</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.325</td>\n",
       "      <td>39.185505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gobstopper</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.453</td>\n",
       "      <td>46.783348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Haribo Gold Bears</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.465</td>\n",
       "      <td>57.119740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Haribo Happy Cola</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.465</td>\n",
       "      <td>34.158958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                competitorname  chocolate  fruity  caramel  peanutyalmondy  \\\n",
       "0                    100 Grand          1       0        1               0   \n",
       "1                 3 Musketeers          1       0        0               0   \n",
       "2                     One dime          0       0        0               0   \n",
       "3                  One quarter          0       0        0               0   \n",
       "4                    Air Heads          0       1        0               0   \n",
       "5                   Almond Joy          1       0        0               1   \n",
       "6                    Baby Ruth          1       0        1               1   \n",
       "7           Boston Baked Beans          0       0        0               1   \n",
       "8                   Candy Corn          0       0        0               0   \n",
       "9           Caramel Apple Pops          0       1        1               0   \n",
       "10             Charleston Chew          1       0        0               0   \n",
       "11  Chewey Lemonhead Fruit Mix          0       1        0               0   \n",
       "12                    Chiclets          0       1        0               0   \n",
       "13                        Dots          0       1        0               0   \n",
       "14                    Dum Dums          0       1        0               0   \n",
       "15                 Fruit Chews          0       1        0               0   \n",
       "16                     Fun Dip          0       1        0               0   \n",
       "17                  Gobstopper          0       1        0               0   \n",
       "18           Haribo Gold Bears          0       1        0               0   \n",
       "19           Haribo Happy Cola          0       0        0               0   \n",
       "\n",
       "    nougat  crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0        0                 1     0    1         0         0.732         0.860   \n",
       "1        1                 0     0    1         0         0.604         0.511   \n",
       "2        0                 0     0    0         0         0.011         0.116   \n",
       "3        0                 0     0    0         0         0.011         0.511   \n",
       "4        0                 0     0    0         0         0.906         0.511   \n",
       "5        0                 0     0    1         0         0.465         0.767   \n",
       "6        1                 0     0    1         0         0.604         0.767   \n",
       "7        0                 0     0    0         1         0.313         0.511   \n",
       "8        0                 0     0    0         1         0.906         0.325   \n",
       "9        0                 0     0    0         0         0.604         0.325   \n",
       "10       1                 0     0    1         0         0.604         0.511   \n",
       "11       0                 0     0    0         1         0.732         0.511   \n",
       "12       0                 0     0    0         1         0.046         0.325   \n",
       "13       0                 0     0    0         1         0.732         0.511   \n",
       "14       0                 0     1    0         0         0.732         0.034   \n",
       "15       0                 0     0    0         1         0.127         0.034   \n",
       "16       0                 0     1    0         0         0.732         0.325   \n",
       "17       0                 0     1    0         1         0.906         0.453   \n",
       "18       0                 0     0    0         1         0.465         0.465   \n",
       "19       0                 0     0    0         1         0.465         0.465   \n",
       "\n",
       "    winpercent  \n",
       "0    66.971725  \n",
       "1    67.602936  \n",
       "2    32.261086  \n",
       "3    46.116505  \n",
       "4    52.341465  \n",
       "5    50.347546  \n",
       "6    56.914547  \n",
       "7    23.417824  \n",
       "8    38.010963  \n",
       "9    34.517681  \n",
       "10   38.975037  \n",
       "11   36.017628  \n",
       "12   24.524988  \n",
       "13   42.272076  \n",
       "14   39.460556  \n",
       "15   43.088924  \n",
       "16   39.185505  \n",
       "17   46.783348  \n",
       "18   57.119740  \n",
       "19   34.158958  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 13 columns):\n",
      "competitorname      85 non-null object\n",
      "chocolate           85 non-null int64\n",
      "fruity              85 non-null int64\n",
      "caramel             85 non-null int64\n",
      "peanutyalmondy      85 non-null int64\n",
      "nougat              85 non-null int64\n",
      "crispedricewafer    85 non-null int64\n",
      "hard                85 non-null int64\n",
      "bar                 85 non-null int64\n",
      "pluribus            85 non-null int64\n",
      "sugarpercent        85 non-null float64\n",
      "pricepercent        85 non-null float64\n",
      "winpercent          85 non-null float64\n",
      "dtypes: float64(3), int64(9), object(1)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated by the above information:\n",
    "Dataset Size: Atleast 8.7. KB\n",
    "85 Entries\n",
    "13 Columns/Features\n",
    "Most of the features are in int64 data type with 3 in float64. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winpercent          1.000000\n",
       "chocolate           0.636517\n",
       "bar                 0.429929\n",
       "peanutyalmondy      0.406192\n",
       "pricepercent        0.345325\n",
       "crispedricewafer    0.324680\n",
       "sugarpercent        0.229151\n",
       "caramel             0.213416\n",
       "nougat              0.199375\n",
       "pluribus           -0.247448\n",
       "hard               -0.310382\n",
       "fruity             -0.380938\n",
       "Name: winpercent, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['winpercent'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data we can see that the winpercent is relativley closely related to whether or not it has chocolate in it. Another way to visualize it is to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['winpercent', 'chocolate', 'peanutyalmondy', 'bar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAHrCAYAAADrHNooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl83Fd97//XmV3SaN8lW5a32PEeRybO4iwkLCFhCVCg0EuhS275tVy4be+vuV1+UCj3BvgBTWkvt7ltaQoF2kIXICUpDklw9thZHNuJ18irrF2zaPaZc/+YkWJ5ZFvLjEay3s/HQ5nvfM98v/OZ8Tejj86c8znGWouIiIiIiMyOo9QBiIiIiIhcDpRYi4iIiIgUgBJrEREREZECUGItIiIiIlIASqxFRERERApAibWIiIiISAEosRYRERERKQAl1iIiIiIiBaDEWkRERESkAFylDmCmGhoabGdnZ6nDEMnT3d2Nrk2Zr3R9ynyla1Pmsz179gxYaxsv9bgFm1h3dnaye/fuUochkqerq0vXppTc0GiCJ44M0Oj3cu3K+vH9uj6l1Ky17Do8QDCWZMfqRqrL3MAb12YmY/n54X5G42luvKKBSp+7xBGLgDHm+FQet2ATaxERubAnjwxwtC/M0b4wyxsqaKn2lTokEQCOD0bYc3wYAK/LyVvWNU9oPzYwyosnRgAo8zh489rmvHOIzFcaYy0ichlqrPQC4HM7qfSpD0Xmj5pyNx5XNv0Yu07PVVvuxu00ADRV6g9CWVj0aSsichnavqKe5Q0V+L0uKrz6qJf5o6bcw0evXUY0mZ40ca73e/nodZ3Ek5lJE2+R+UyftvNE5z0Pzur47nvvKFAkInI5OD44ynefO8HS2nJ+8U0dOBxmQns8lWb/mSCNfi9L68pLFKUsRql0hp8fyo6xvu3K5rzkOZnO8PjBfkbjKd6yrpl6v5JrmTvBWJLDvSGW1VfQMINrT0NBREQuQ9965jgvnhjhRy+f4WBvKK/90df6ePxgP//8wmkC0WQJIpTF6sRQhEO9Ic4GYrxwYjivvXtglCN9YXoCsfGx1iJz5YcvneHnhwb4/p5TZDJ22seXJLE2xpQbYx40xjxmjPk3Y4zXGPM1Y8wuY8x9pYhJRORy0pTrafG6ndSU5VdVsOf+vpj+7w6RGWuq8lHhdWIMdNZXTNpe7nHiMIbOBn2bInNr7OPQzvBzsVRDQd4OPGut/Zwx5g+Ae4AKa+0OY8w3jDHbrLXPlyg2EZEF75ev7+TKtipaq3201pTltd+ytomGSi9NlV6qy1XOTOaO3+vi49cvJ5nOUO7JT0Oqy9x8/PrlpDOWMo+zBBHKYvauTW0c7A3R2VCeN4RuKkqVWB8Frs5t1wBhYGfu/k5gO6DEWkRkhrwuJztWX3gtA5/bybbOujmMSOQNbqcDt/PCX5qPVQ0RmWvV5W7etHzmn42lunIPA9cYY/YDXUAKCObaAkDtZAcZY+42xuw2xuzu7++fm0hFRERERKagVIn1LwMPW2vXAw+S7TmvyrVVAZPOVrDW3m+t7bLWdjU2XnJVSRERERGROVOqxNoAQ7ntgdztrbnb24Bn5jwiEREREZFZKFVi/R3gA8aYx4CPAF8HYsaYXUDGWvtcieISEbksWGs52BNkIBy/YPvJoQjBmErtydxLpDKMxlOlDkMkTyKVZv+ZAJEZXp8lmbxorR0B3nbe7k+VIhYRkcvRt54+zoOv9FDucfKl92+i8bwV7n5+eIAXjg/jdTv42HWdk1ZnECmGUCzJd587QSSR5u0bWljbUnXpg0TmyL0/eY39Z4K0VZfx1Q9uxpjpVQbRtFsRkcvQsYEwAJFEmp5ALK99JJIAIJ7MEEmk5zQ2Wdz6Q3FG42msheODkVKHIzLBiaEoAD3BKIlUZtrHq4tCROQy9OE3LeOBp7tZWlvOxvbqvPYbVzfidTlorvLNaNlekZnqqCtnbUslgWiSq5dNWgRMpGR+aXsHD+07y/YVdXjd06+jrsRaROQydEVLJV+4a+MF22srPLx9Q+scRiSS5XI6uH2jrj2Zn25e08TNa5pmfLyGgoiIiIiIFIASaxGRy9DwaILv7znJU0cHLviYUCxJMj39MYQis2Gt5ckjA/zklZ5Jq9JkMpZdh/t5aF8PYVUOkTlmrSUQTZLJ2Bkdr6EgIiKXob/8+VH+Y38v5R4nf/7hq+hs8E9o33N8iJ8fGqC6zM1HtnfgdU1/LKHITBzrH+V7z50gnsoQS2a4a2v7hPYj/WH+4fmTJFIZUmnLnZvbShSpLEb/caCXA2eCLKkt4xe6lk77ePVYi4hcho71h4mn0oxEk5wZya8KMlaNIRBNEoiolrXMnVAsyUA4TiCa5GwwmtceiCYZzLX3BvOvXZFiOpH7bDw1HCU1g2/01GMtInIZes9V7fSF4rRU+diytCav/ZoV9cSSGVqqvTRWqiqIzJ3ljX6ubK1iJJLkhlUNee2rm/ysaakkFEtx7cr6EkQoi9kNqxvYc3yYK1srcTmn3/+sxFpE5DJU5naxeUkNFV4nyXT+WMH2mjI+fE1HCSKTxS6eSuNxGqp9LkKTjKGOJtNUeF14XU5CMY2xlrm1tqWS5iofVb6ZpchKrEVELkP7zwR47WwIj9NBKJ6kutxd6pBEABgMx3nldJBUxrKssYLrVk7stU6kMrgcDlwOiM9ggQ6R2Xho31leOxuircbHB7dNv/NBibWIyGWoucpHS5UPv9eJ0zG9JXlFisnrcrK0roxYIkNDRf4wpGX1Fdy8ppFQPMn25RoKInPr1HBu5cVAjHTGTvvzU5MXRUQuQy1VPiLJNMZhqFVvtcwjDX4v1hqiqQwt1b689lAsyZ7jw7x0IsCpYS15LnPr5jWNtNX4uHlN04w6JdRjLSJyGRqKJFjXWpXdHk3SVqOPe5kf+sNxWqp9tFT7GAgn8trPBmLjY6uP9Y+yotGf9xiRYlndXMnq5soZH69PWhGRy9DWjlqGRxM0VvporsrvFRQplY66cpY3VBCMJSetWNNRX86y+nJG4yk2La0uQYQiMzfrxNoY8ylr7X2X2iciInMnYy2pjCWVmXzy17H+MD97rY/mKh/v2NiqcdgyZ9xOB++5qv2C7V6Xk/duXTKHEYm84YUTw+zuHmJtSxU3XtE47eMLMcb6lyfZ97ECnFdkQctkLD96+Qx/8egR9p0OlDocWWQeea2Pn73ay09e6aFnJH8Rju89d5K/e7qb//PzY/QENI5V5o9oIs3fPPk6f7rzEKcnuXZFiunHL5/hycMD/NtLp+d2gRhjzC8CHwaWG2N+eE5TJTA40/MuVJ33PFjqEGSeCcVSHOkLA/DyqRE2tOsrTZk7u7sHeeVMEJ/LwdBogiV15RPanzzSz9lAjIFQgpMDoyyprShRpCIT7T8TYOeBXtIZS7XPzcdvWF7qkGQReX1glCP9owRnWEN9NkNBngJ6gAbgK+fsDwF7Z3FekctCpc/FisYKTgxG2KikWuZYIpUtE2UMRBP5vyDKPE4cxuB0GjxuTbeR+cPtNIRiSeLJDMbkL24kUkwNfi+j8RS1FZ4ZHT/jT1Nr7XHgOHDtTM8hcjlzOAzv3nLhcYQixbSxvYbugVGqyty01pTltW9fUc9IJLtwTHtt+SRnECkNn9tFZ30FiXSGOr8m3src+tCblvLkkQE2tleXZklzY8x7gS8CTYDJ/VhrbdVszy0iIjPT1VnL6ZEI9RVeGirzF+F40/I6+kJxGv1ealTnWuaRpkova1urSKQyrGzUECWZW2Ol9pbVz+zaK8T3f18C3mmtfbUA5xIRkQKIJNJUl7lxOgzxZIZyT357lc+NwxjiqQw+t7M0gYqcp7bCw8eu6ySeylA3w6/jRWbqhy+doT8Up8wzzN07VuAowcqLvUqqRSYXiCY50hea0cxikdmw1lLuceFyGiYbpZrOWOKpDMm0ZdIHiJTQaDxFMJosdRiyCI19HNoZfi4Wosd6tzHmH4B/BeJjO621/1yAc4ssWPFUmu8+d4JoIs2alkresbG11CHJInLTmkbqKjw0+L2T9vq5nA5iyTQ+twOnUzWsZf7oC8b47nMnyVjLjVc0cPWyulKHJIvIuza1cbA3RGdD+bR7q6EwiXUVEAHees4+CyixXkBmWy6w+947ChTJ5SOZtsSSaQDC8ZmV7RGZqRODEZ45NkiD30t7bRnu8ybhvD4Q5tRwhOGIi9F4Er9XlUFkfhhNpMnkugtDMyx5JjJTB3qCPPf6EMORBG9b3zLt42f9SWqt/fhszyFyOfJ7Xdy+oZWTQxG2LqstdTiyyBzoCZJMW3oCMfpDcdrOqwzi97ppqPTmEmr1WMv80Vlfzo7VDYTjKbavqC91OLLIvHJ6hIy1HDgT5Na1TdOuDDLrMdbGmCuMMY8YY/bl7m8yxvzhFI77aO64x4wx7caYrxljdhljtBS6XDbWtFRy27pmTcCROXdFcyX9oTg+t5OmSaqCbFlajd+bLWvW4M9vFykVYwxdnXXcvKZJk2plzq1q9NMbjLG0rmxG5fYKMXnx/wD/HUgCWGv3Ah+62AHGmHbgJmvtrdbam4FmoMJauwPwGGO2FSAuEZFF68RQhMZKL/FUmsAkk8BODEVpqvQRS2YIxTRJTEQE4PRIlOYqH32hOJnM9GcwFmJQXbm19jljJnyVeKlBUW8DnMaYR4ADwGvAzlzbTmA78HwBYhMpGWstD+07y/GhCDeubmRdm0q7y9wxFgbCcSo8Lhwmf6hHXzDOnuPDVPpczOB3h8isnA3ECMWSrGryc17+QCyZ5l9fPE04nuKOTa20VucvcCRSLGlr6Q/Faaqa2Td5heixHjDGrCRXocQY836yS51fTDPgsdbeSnbiYw0QzLUFgEkHpBpj7jbG7DbG7O7v7y9A6CLFE4ymeO1siGgizYsnh0sdjiwyQ5E4r/YEOdIfnrQ9kkwxGk8RT6aJ5ybZisyFvlCMf3j+JD/e28Mzx4by2k8ORegJxAjFUuw/HZzkDCLFc2YkyoGeAKeGIkzSJ3FJheix/k3gfmCtMeY08DrwS5c4JgA8ntv+GdBFtroIuduRyQ6y1t6fey66urrUx3KO2Vb1kMKr9LnoqCvn5HCEda3qrZa5dbA3jNvpYDSe4vRIlNrzxvmnMxavy4ExZrwCg8hciCcz49dcbJI/6tpqyqgpdxNJpLkitwqeyFzpHojgdTk5PRIjkcrgneY4/0JUBTkG3GaMqQAc1trQFA57Cvj13PYWsr3dtwL/CNwG/O1s4xIpNYfD8L6rl5DJ2BnVwhSZjXdsaGUkkqClqozVzf689puuaCSVztDg99JY6StBhLJYLa0r59YrmwhEk2zrzK9RXeF18fHrl2OtzRsmIlJs79jYyqOv9bF5afW0k2ooQGJtjPkfwJestSO5+7XA71hrL1gZxFr7kjEmaox5DBgAPgx82RizC3jZWvvcbOMSmQ8C0ST9oRid9RUzml0sMlMbl1TzC+mlNFf58LryfzmsavRz8GyIK5r8eFy6NmVubVpSc9H2p48OMDSarSOsz06ZS++5qp23b2jBO8PPxUIMBbndWvv7Y3estcPGmHcAFy25Z6393fN2faoAsYjMG+euvLi2pZLbtfKizKHvPnucH+3toarMzRfft4nmqom90n/+6BGeOjKA1+3kqx/cQnuNJojJ3Igl03x/zykC0SR3bmplWX3FhPaXTgxz387DWKAvFOfj1y8vTaCyKO063M+jr/Vx9bJa7tjUNu3jC/FnoNMYMz510hhTBqgoqix65668qNXDZK49f3yY3mCMo31hTg1F8tqP9ofpD8fpGYkSjCRKEKEsVqdHovSH4iRSGV7tyR89GktlGBv1P9kYbJFi+qfdJ9l/Jsg/7T5FMjX9668QifW3gUeMMb9qjPkV4KfAAwU4r8iC5ve6uH5lAzXlbm5a01jqcGSR2dheQ7nHSUu1j+bq/DHU1yyvw+91sbyxgsYqjbGWudNeU0ZLtY8yj5P1k5QhvWZ5HdtX1NFZX85H3tRRgghlMast9+J0GKrL3Tgc00+TCzF58UvGmL1kJx0a4PPW2odne16RhS6aSPGNnx/l7EiUQCTBp9+yptQhySLicxvcTgcup4Nyd/5H/ZNHBukejHA2GGM0ntLqizJnfG4nv3iRhPnpYwM88FQ3qYyl0ufiD+9cP4fRyWL3azuWs/dUgCua/ThnUHhgVom1McYJPGytvQ14aDbnksVtNuUCu++9o4CRFM6ZkRiHekJYLLuODCixljn1yqkAwViKaDLDiaFR6vwTy+0d6AlgrSWayPB891DeOFeRYhkbYx2MJblzYxsd9eUT2h850Eckkf0K/okjg6UIURax0yNRjvWHcTsNq2dQ7nFWQ0GstWkgYoypns15RC5HrdU+Vjb68ftcbF/eUOpwZJHpqKug0uuiwe+hptyd137LmiZ8bidNlR52rNL1KXNnbIx1PJnhQE/+AjDvvqqNmnIPZR4n79w8/cljIrOx99QIqYxl/5kgqXRm2scXoipIDHjFGPNTYHRsp7X2vxTg3CILVrnXxWfftY69pwO8dV1zqcORRebOzW04HYbmKh/tteV57Z9913q2LatlXXsVzVoyWuZQe00ZzVU+AtHkpGOsNy2p5Rsf2UpvMMbbN6iaksytzUtqeL57iLUtVTMq9ViIxPrB3I+InCMST/En//4q/aE4x/pH+a9vuaLUIckisqrJzydvXX3B9m89fZwfvnyGmnI3933oKmrKPRd8rEgh+dxOPnzNhcdYvz4Q5ksPHySeypC2qNda5tQ1K+q5ZkX9jI8vxOTFB3Il9jqstQdnez6Ry0VfKMahsyEy1vLMMY0TlPll15EBBsJxBkcTHOsPs3VZ/gp4IqXw4olhTg1nS0T+/FC/EmtZUGZdbs8Y807gJXKTF40xW4wxP5zteUUWuoZK33ilhSua8peUFimlK1sqAUN1mZuOuvyhIiKlsra5knKPC4cxbGjPHyoiMp8VYijIZ4E3AY/B+HLlC26ZpNlUpRCZTMZa1rVV0R4to0MVF2SeWVJbztaOGvxeF9OfniNSPG6Xk81La0ik0jRWqsa6LCyFSKxT1tqAMRNq/dkLPVhksShzO1nV5GckkmR1s3qsZW4d6Qvz8P6zNFZ6ueuqdtznTcJZ2eSnLxTH73VR5cuvGiJSLLFkmh+8cIpgNMUdG1vzyu01+L0sb6ggkcrQqU4JmWPPHhvk+e4h1rRU8ZYZFB4oRGK9zxjzYbJLm68G/gvwVAHOK7KguZ0OPnxNB8Foiga/JobJ3PrZa2f56f6zVJW7uW5lPUvOqwxSX+GhNxijqtmP11WIRXhFpub0SJS+YByAAz3BvMS6tsLD1o4aRiJJVjQqsZa59dMDZzk2EOHEUIRb1jROuzJIIT5NPwmsB+LAd4Eg8OkCnFdkwfO6nDRWejnvGx2Ronv5ZIATwxEO94bpD8by2u/fdYzdx4f4wZ5THO4NlSBCWazaa8poqvLidTtY15o/hvr1/jD/uPsUP97bw+OH+ksQoSxmsVSGaCK7uNZMFKIqSAT4A2PMF7N3rT6hRURKzOtyUuZ24nI6cE/SIx1Lpokm0qScGrknc8vndvKRa5ZdsL0vHOfMSBSA7oHRCz5OpBhuWNVIfYWX9tqy0tSxNsZsA/4GqMzdDwC/Yq3dM9tzi4jIzLz5yiZOj0Ro8HsnXa78trVN9AZitFT5WKKqIDKPrGz0s3lJNbFkhmuWqwykzK1VTRX0hWKsmcFy5lCYoSB/Dfw/1tpOa20n8JvANwtwXpEFb/+ZAA/tO8tAOF7qUGSRSWcs61qrWVpXTjieymsPxpL4vS5cTjNpu0ip1Fd4eNPyOjYuqWZNi8rtydx67GA/g+EEjx7sI52Z/jd6hZi8GLLW7hq7Y619whij4SCy6AWjSb788EH6gjFuuqKR37v9ylKHJItIW00Zx/pHKfc4qS7Lr/qx70yQ/WeCVHhdROOp3HeOInMjmkgTT6UnXfHz1Z4gf/3E60STaay1fGDbhVdpFCm0piovvcEYHXUVOB3Tnx9ViMT6OWPMX5KduGiBDwKPGWO2AlhrXyjAc4gsOIPhGM8eGySZzhBJpJRYy5za1llHhcdJU6WPck/+R333wCgjkQSRZIpgVD3WMncC0STfefYEsWSat6xrZkN79YT2Q70h9p4OkMlYnjgyoMRa5pQDg7Uwg5waKExivSV3+5nz9l9HNtF+cwGeQ2TBGR5NkEpnsBZCMSUuMreePjrIM8cG8bmdfPTaZVR4J37cnx2JkspYMok0/eEoUFOaQGXRGQzHiSXTAJwZieYl1qeHIsSTaazNbovMpbPBGBVeF/3hOOmMnXavdSGqgtwy23OIXI7aayuorfAwGk9zxQwnQYjM1Ni4/lgyTSiWykusa/1e+sIJXA6D36sFYmTudNZXsLG9mmAsybbO/MmJdX4vXpeTjLU0aOVFmWM3r2nkheMjrGmpLM1QEGOMF3gf0Hnu+ay1n5vtuUUWsroKN9etbKB7cJTbN7SUOhxZZK5f1QBAY6WXlur85OQ9W9r426eO01zlZV1bdV67SLE4HIbbLrKi3U1XNPLd508SjqW4a2v7HEYmAquaKlnVNPPOsEIMBfk3IADsIbtIjIgAkUSGpXXlNFf5cM6gFqbIbNRVeHjn5rYLtlf6PLxtfQtup4PRRBq/ljWXeWI0kWbH6gbSGYvLoc9OWVgKkVgvsda+vQDnkQWs854HSx3CvFPpcxGOpTjQE2Rju3oEZW71hWLsOjRAY6WXHasb8lb/dDosO1/tZWltGXXlq0oUpUi+Br+H544NEoiluGl1Q6nDEZmWQvwp+JQxZmMBziNyWRkYjfPyqRGGRrP1MEXm0jPHhjgxFGHP8WHOTrKk+fd3n2Z4NMGrPSFePhUoQYQik3vk1T66ByMMhuP8055TpQ5HZFoK0WN9A/AxY8zrZIeCGLJLm28qwLlFFqxkMs3hvjCJVBozw7I9IjPVVu3jaF+YCu/kdazPBmMEokmcDoO1mRJEKDK5SDLFcCSJtZbeoEaYysJSiMT69gKcQ+SyE02myWQsmQykUkpcZG51ddaxotFPuceJz+3Ma/e6HDgMOA2kdXnKfJIxOA1kDLhdGmMtC8uMr1hjzNg6o6EL/EzlHL9tjHkit/01Y8wuY8x9M41JZD5xOR1UeFx43Q6qK/JXFxMptroKz6RJdbbNi8/tpMLrvuBjREqhutxFuddFmdtFgz47ZYGZTY/1d4A7yVYDsWSHgIyxwIqLHZwr07c5t70VqLDW7jDGfMMYs81a+/wsYhMpudbqMravquPMUJS3b2wtdTgiE9yxqZVoKkWD38uqJn+pwxEZ19VZx5YlNUSSaW7XZ6csMDPusbbW3pnbfAL4n8Dt1trluZ+LJtU5vwY8kNu+FtiZ294JbJ9pXCLzhdftZHN7NTXlbrZ11pY6HJEJrl5WQ125hw1t1Sq1J/NKc6WPFY1+Gis8bGiruvQBIvNIIcZYf5PsBMavG2NWAC8Cu6y1FxzSYYxxAzdZa//CGPM5smvpHs01B4D1FzjubuBugI6OjgltKve2eM3237773jsKFMlER3qDfOWnh0mlMxzpH+Wx/6ZFSmXunBiMsPPVXhoqvdyxsTVvBbHf+NYLdA+O8tjBfrYuqeG6KxpLFKnIRN9+9jh//+xxrIVQIsUDv3JNqUOSReSlkyPs7h5ibUsVN8yg3OOsZwVYa38GfAH4I+CvgG3AJy5x2H8iO5RkzAgw9mdpVe7+ZM91v7W2y1rb1dioXwIyv4ViSdKZDNZCJJEudTiyyLx4cpjB0ThHekP0TlJubziSIGMhlbYcH46UIEKRyQ2G46QzlrTNEIgkSx2OLDLPvT5IKJbi+e4hUjOY2T3rxNoY8wjwJPBB4CCwzVq79hKHrQE+YYx5iGzvdANwa67tNuCZ2cYlUmpXttbQVOnF5TRct6Ku1OHIIuPAsOf4CEf7w/i9+ZMT17VWYgx4XIab1mgRDpk/3nxlEy6nwRjDtSvrSx2OLDJrWrL9vCub/LhmsGpyIYaC7AWuBjaQHcYxYox52lobvdAB1trfG9s2xjxhrf1jY8x9xphdwMvW2ucKEJdISfWGojgcDuoqPPSHE6UORxaZDJZtnbU4DITjaarKJraPRJOUe5w4jOHg2TBtNRWlCVTkPM91D+N2OnA54EBPsNThyCJz0xWNXLuiHs8MSz3OOrG21v5XAGOMH/g42THXLYB3isffkLv91GxjEZlPKr1uGvweAtEkS+vKLn2ASAFt7ahleDRBY6WP5ipfXvv6tmp6g3EqvC6WNyqplvljy5JqKn0ukinLVUtrSh2OLEIzTaqhAIm1Mea3gB1ke62PA38D7JrteUUWutoKD9evbOBAT5C3rlPJKJlbS+vK+dj1yy/YftdVSxiKJFheX8HSWiXWMn+sb6vmxisaCUSSKlUqC04hljQqA74KrLXW3mqt/ePchEaRRS0YTXE2GMPpMLzWq68zZX557WwQp3EwNJpkIKxlo2X+OD0SHZ/wffhsuMTRiExPIYaCfLkQgYhcbiyW7oFR+kJxWqs1FETmVl8oxq5DAzRUerlxdQPGTCy3d3xwlN3dg9RWeMhYW6IoRfJFE2leOj5MNJXmqqVaA0AWlkL0WIvIJOKpNCeGIgxHEhw4Eyh1OLLIPHNsiBNDEV44PszZScrtPfv6MKF4itMjMY4PqldQ5o+XTw7TG4oTiCZ54mh/qcMRmRYl1iJFEk2ksdZigOQMamGKzEZbdXbCYoXXSXVZ/sqKTgNgMOP/FZkfHBiMAWNM3sJGIvNdIcrticgkaso9LKmtYCAcZ0N7danDkUWmq7OOFY1+yj1OfO78OtY7VjcwEk1SU+6mo16TF2X+2Lyslo66cmLJDDdpRVBZYJRYixRJmcfJ0royLJYVKmcmJVBX4blgW2eDn6ZKH83VXip9+T3aIqXSXOmlraaM0USKZXX67JSFRYm1LHqd9zw4q+O7771j0v2BSJJTw1GS6Qz7T4dm9Rwihbbv9AjJdIazgRhnA1FWNVWWOiQRAA71hhmJJElby94zAW5e21TqkESmTIm1SJH43A78XhdOh6G8qWXiAAAgAElEQVS2Qj2CMr/U+r2UeZy4nQ6q1GMt80id34PX7cRaS/1FvnURmY+UWIsUSVWZh8+9Zz2Hzoa4YbXGCcr88ls3r2JzezWdDRU0TbIyo0iprG+r5o/uvJKhcIIbVjeUOhyRaVFiLVJE1T4PHfUVmtku847DYeioL6emXD2CMv80+L2UTTLpVmS+U2ItUiSxZJrvPHeCWDLNmpZK3qGleWUeefxQHy+fDOBxOfjl6zrxe/XrQOaH3mCM7z53Amuz1Wu6OutKHZLIlKmOtUiRpDKWeCq7LG84nipxNCIThePZazORypBIqc66zB+RRJqxxUBHc0ubiywUSqxFisTvdbGy0U8smWbLkppShyMywab2auKpNEtqyy5alk9kri2rK6eqzEU6Y9nQVlXqcESmRYm1SJGEYkn2nwkQSaR5vnuo1OGITPDCiWEiiTRH+sL0h+KlDkdk3LGBUXpGYoRiSV4+NVLqcESmRYPqRIrEkK3HOhpPafyqzDs9IzEOng3hczu1oLnMK+lMhgNngqStZUObVq2VhUW/7UWKxRjWtVYRSaTobCgvdTQiEyypLWNDexVelxOjzFrmEbfTwaal1aTSlsYqb6nDEZkWJdYiReL3urhzcysnBiNcvay21OGITHDz2iYqvC6aq3zU+5W8yPyxvKGCW69sJhxLsX1FfanDEZkWJdYiRbS2pYq1LZp8I/NPdZmb29Y1lzoMkTzGGLapxJ4sUJq8KFJE+04H+MkrPZocJvPOSCTBQ/t6ePHEcKlDEZnAWstTRwf46YFeIgmVKpWFRT3WIkUSiiXZ+Wov1kIwluSD2zpKHZLIuMcP9XOsf5RXe0IsrSunQcNBZJ44NjDKs8eylZRcTsMta5pKHJHI1KnHWqRIvC4nfcE4+04HSKa1AIfML2NLmXvdDso9Wjpa5k46Y3lo31n+cfdJBsP53+ZVeJwc6w9z4EwAp2bWygKjHmuRIokm0/i9LtJ+D6igmcwzN65uoK7cQ2uNj3KPfhXI3Dk+OMqrPUEAdh8f5m3rWya0h2IpGv1eYum0OiVkwVGPtUiReJyG0yMRugcjBKPJUocjMsFzrw+x89Ve/vXF08SSWjZa5k5DpZdyT7bM49La/FKkXpeTowOjHOsfJZFSYi0Li7opRIokkbasaPSztDYz/rW7yHxxJhAFsr2DwWgSn1vDQWRuVPncfOz6ThKpDJU+d157Ip1mQ3sVGQsel/r/ZGFRYi1SJNVlbq5f1cCJwQjXrlQtVplfrl3RQCrdT3OVj6YqX6nDkUXG63LidU3+x9zyBj+bl9QQjqfoWqaye7KwKLEWKaLtK+q1wIHMSy3VPn6ha2mpwxDJ43QY3nreuGuRhcJYa4tzYmPagB8D6wC/tTZ1TtsG4H+TndH1CWvt3sn2Xez8DQ0NtrOzsyixi8xGd3c3ujZlvtL1KfOVrk2Zz/bs2WOttZccm1TMHush4FbgXyZp+zzwi0AG+F/Auy+w74I6OzvZvXt3IeOdkRdODPPE4QGW1Zfzrs1tmPNKA70+MMq/v9JDdZmblY0VPPf6MCsaK7hzU2veY8fEkml+8MIphkcTvGNjKysa/eNtoViSf9p9ingqw3uuaqO1ugyAR1/rY++pAJuXVpNKW3Yd7mffmQDlbhdXNPtpqS7jfVcvoa7iwmN9j/SF+fHLZ3j1bIhIPMnGJTW8Y0Mr/55bRMLldHDr2mZ+aXsHLqeDvmCMbzx2lGMDo9x2ZRNvXd/Cv710GocxvHfrEgLR5Phrf//VS/C5ncSSaf5p90mCsRR3bmolGE3x6ME+hiMJXjk1QiyZYX1bFfV+L1uW1oz3WvzklR4O9YbZvqIOt8vBE4cHiCXTeJwONi6p5obVDfzFz47w6MF+Kn1OPritY9J/j56RKJ/78QGiiTSfvHUVV0/ha8ajfSH+9JHDjMbT/NoNy7luVQOQXcTgR3t76B4Y5fpVDePLlnd1dc2La1NkMmPXZ+c9D47v+//ft4H3b1tWwqhkMfn+88f53R/sA2BVQzk7f/cW4I1r809+9Ap/9eQJAOrKXLzwmbeVLFZZfM79bOy+947xbWPMC1M5vmizAqy1MWvthZb0qrPWnrTWngaqL7JvAmPM3caY3caY3f39/cUIe9r2nw6QzliO9Y8SjuevEPVqT5BEKkN/KM7TRwfJWMuRvjDRi8zC7w3G6AvGSaYtr/aEJrQdH4wQiCaJJdMc6g2P73/ldICMtew7HWDfmQCnhqP0BeMMjMY51BsmHE9xrD98/lPlxToUSXBicJRQLMXxwQhPHBngbCBGbzBOIJLktbNBBkcTABzuC3NyOEIsmWb/mSB7TwUYjacJxVK8PhDmtXNe+9lADIDTI1EGwgkSqQyvnQ2x70z2/dvdPcRIJMlwJMGBnhDDkQT7zwRJZyzxVJrXzoayr+9McHz/SydHiKXS7Dsd5GwgxsHeEMFokr5Qgr2nAsSS+bPJ95wYZmg0QTSZ5okjgxd9P954b4P0BeOMxlM8feyNY0YTaY72hUlnLAfOBKZ0LpH56DM/3FfqEGQR+dojR8a3jw5E8tq//ezJ8e2hqFZelNL56f4z0z6mVNNtHZNsT7ZvAmvt/dbaLmttV2NjY9GCm47NS2vwuBysbanE783/AmBDWzXlHiftNWXceEUjHpeDK1urKLvIDPzW6jLaa8oo8zjZ0F41oW15QwUNlV4qfS6ubKkc339VRzaOrR21bFlaw4rGCtprymitLmNDexW15W5WNfnPf6qJsbZX01TlZXVzJXV+D6uaKrh5TSNL68pZUltGQ6WHTUuqqc/1eq9pqWRFo59Kn4stHTVs7aihptydfa7GStbnXntbjY/WmuzkqGxMPiq8Tta1VrF5SQ1et4PrVzbQWOmlqdLHliVV2dulNTgdBq/LyYb2ajwuB1uW1rBlSfa1vqmzDr83+9yt1WVsbK+h3u+hvcbH1R01lE2y6MW2zjpaqn1U+lzcfEXDRd+PMVs7ammvLaO23MOO1W8cU+FxsralEo/LwealNVM6l8h8dN9dW0sdgiwi//3ta8a317ZU5LX/5s3Lx7dbK1VRSUrnLevbpn1M0cZYjz+BMY8Bt503xvpxa+1NY+3W2psn23ex83Z1dVl93S7zkYaCyHym61PmK12bMp8ZY/ZYa7su9bhSVQUZMsYsITueOnCRfSIL3rnjtWbi3DFeIiIiMn8VLbE2xriBnwCbgYeNMZ8DbrDWfgH4DPA9shVAfjN3yGT7REREREQWhKIl1tbaJHDbebsfz7XtBW447/F5+0REREREFgqtFSoiIiIiUgBKrEVERERECkCJtYiIiIhIASixFhEREREpACXWIiIiIiIFoMRaRERERKQAlFiLiIiIiBSAEmsRERERkQJQYi0iIiIiUgBKrEVERERECkCJtYiIiIhIASixFhEREREpACXWIiIiIiIFoMRaRERERKQAlFiLiIiIiBSAEmsRERERkQJQYi0iIiIiUgBFTayNMV8zxuwyxtx33v7vGWMeM8Y8bYx5Kbfvs8aYl3P7f7uYcYmIiIiIFJqrWCc2xmwFKqy1O4wx3zDGbLPWPg9grf1Q7jF3AVefc9jvWGt3FismEREREZFiKWaP9bXAWJK8E9g+yWPuAv75nPtfNMbsNMZsKWJcIiIiIiIFV8zEugYI5rYDQO25jcYYF7DRWvtCbtefWWuvBj4BfH2yExpj7jbG7DbG7O7v7y9S2CIiIiIi01e0oSDACFCV267K3T/XLcBjY3estUO528PGmElPaK29H7gfoKuryxY2XBGR+afzngdndXz3vXcUKBIREbmUYvZYPw3cmtu+DXjmvPa7gH8Zu2OMqcrdNlDchF9EREREpOCKlljnhnjEjDG7gAxwwhjzBwAm2yV9LfDEOYd82RjzJPAj4J5ixSUiIiIiUgxF7Rm21n7qvF1fyO23wFXnPfY/FzMWEREREZFimlKPtTGm2Rjz18aYn+TurzPG/GpxQxMRERERWTimOhTkb4GHgbbc/UPAp4sRkIiIiIjIQjTVxLrBWvuPZMdKY61NAemiRSUiIiIissBMNbEeNcbUAxbAGLOdbG1qERERERFh6pMXfxv4IbAyV7mjEfiFokUlIiIiIrLATDWx3g/cBKwBDHCQ4tbAFhERERFZUKaaHD9trU1Za/dba/dZa5NkF4AREREREREu0WNtjGkB2oEyY8xVZHurIbtEeXmRYxMRERERWTAuNRTkbcDHgCXAV8/ZHwJ+v0gxiYiIiIgsOBdNrK21DwAPGGPeZ639wRzFJCIiIiKy4Exp8qK19gfGmDuA9YDvnP2fK1ZgIiIiIiILyVSXNP/fwAeBT5IdZ/0LwLIixiUiIiIisqBMtSrIddbajwLD1to/Bq4FlhYvLBERERGRhWWqiXU0dxsxxrQBSWB5cUISEREREVl4prpAzI+NMTXAl4EXyC5t/ldFi0pEREREZIGZ6uTFz+c2f2CM+THgs9YGiheWiIiIiMjCcqkFYt57kTastf9c+JBERERERBaeS/VYv/MibRZQYi0iIiIiwqUXiPn4bE5ujPka0AW8YK391Dn7/xa4kuykyPuttd/JTYr8Ntk62f+ftXbnbJ5bRERERGQuTbWOdbUx5qvGmN25n68YY6ovccxWoMJauwPwGGO2nfeQj1hrb7bWfid3/x7gD4G35m5FRERERBaMqZbb+xsgBHwg9xMEvnmJY64FxnqddwLbz2mzwN8ZY35kjBlbaGYT8LS1NgyEjDGVU4xNRERERKTkplpub6W19n3n3P9jY8xLlzimBjia2w6QXQ59zO9Ya4eMMTcAXwHeDzittfacx9eSTebHGWPuBu4G6OjomGLoIiIiIiLFN+UFYnJJMADGmOt5Y9GYCxkBqnLbVbn7AFhrh3K3TwAtud3pc46d8PhzjrvfWttlre1qbGycYugiIiIiIsU31cT6E8BfGGO6jTHdwJ8Dv3GJY54Gbs1t3wY8M9ZgjKnK3a7hjQR6rzHmWmNMBVBlrQ1OMTYRERERkZKb6gIxLwGbxxLiqSS91toXjDExY8wu4GXghDHmD6y1XwD+3hhTS3as9Sdyh3wJ+DugDPjM9F+KiIiIiEjpTCmxNsb8D+BL1tqR3P1asuOkL1q949wSezlfyO3Pq49trT0FvHkq8YiIiIiIzDdTHQpy+1hSDWCtHQbeUZyQREREREQWnqkm1k5jjHfsjjGmDPBe5PEiIiIiIovKVMvtfRt4xBjzTbLjon8FeKBoUYmIiIiILDBTnbz4JWPMXrLVPQA+b619uHhhiYiIiIgsLFPtsQZ4EXCT7bF+sTjhiIiIiIgsTFMaY22M+QDwHNkVEj8APGuMeX8xAxMRERERWUim2mP9B8A2a20fgDGmEdgJfL9YgYmIiIiILCRTrQriGEuqcwancayIiIiIyGVvqj3WDxljHga+m7v/QeDfixOSiIiIiMjCM9WqIP/NGPM+4HrAAPdba/+lqJGJiIiIiCwgU64KYq39AfCDIsYiIiIiIrJgTbUqyHuNMYeNMQFjTNAYEzLGBIsdnIiIiIjIQjHVHusvAe+01r5azGBERERERBaqqVb26FVSLSIiIiJyYRftsTbGvDe3udsY8w/AvwLxsXZr7T8XMTYRERERkQXjUkNB3pm7tUAEeOs5bRZQYi0iIiIiwiUSa2vtxwGMMQ8An7LWjuTu1wJfKX54IiIiIiILw1THWG8aS6oBrLXDwFXFCUlEREREZOGZ8pLmuV5qAIwxdUyhoogx5mvGmF3GmPvO2/+XxpgnjTFPGGM25fZ91hjzsjHmMWPMb0/nRYiIiIiIlNpUy+19BXjKGPN9smOrPwB84WIHGGO2AhXW2h3GmG8YY7ZZa5/PNd9rrX3dGLMauBd4X27/71hrd07/ZYiIiIiIlNaUeqyttX9HNvntBfqB91prv3WJw64FxpLkncD2c873em4zCaTPOeaLxpidxpgtU4lLRERERGS+mM6S5geAA9M4dw1wNLcdANZP8pj/CfxZbvvPrLWfzfVi/w2w4/wHG2PuBu4G6OjomEYoIiIiIiLFNdUx1jMxAlTltqty98cZYz4NHLDWPgFgrR3K3R6+0Amttfdba7ustV2NjY3FiVpEREREZAaKmVg/Ddya274NeGaswRjzVuA64E/O2VeVu21gGj3pIiIiIiLzQdESa2vtC0DMGLMLyAAnjDF/kGv+OrAceNQY85e5fV82xjwJ/Ai4p1hxiYiIiIgUQ1F7hq21nzpv1xdy+9dM8tj/XMxYRERERESKqZhDQUREREREFg0l1iIiIiIiBaDEWkRERESkAJRYi4iIiIgUgBJrEREREZECUGItIiIiIlIASqxFRERERApAibWIiIiISAEosRYRERERKQAl1iIiIiIiBaDEWkRERESkAJRYi4iIiIgUgBJrEREREZECUGItIiIiIlIASqxFRERERApAibWIiIiISAEosRYRERERKQAl1iIiIiIiBVDUxNoY8zVjzC5jzH3n7d9gjHnCGPOkMWbThfaJiIiIiCwUrmKd2BizFaiw1u4wxnzDGLPNWvt8rvnzwC8CGeB/Ae++wL5Lstay/0wQr8tBXYWH7sEIq5v9jMZT9ARirGutwud2TjhmeDTBsYFRWqt99ARiLK0ro6nSRyyZ5kBPkNZqH63VZROOea57iNf7w7xjYyvh3Ln9HifPvD6Ez+VkfWsVaSwOY3A5DWtbqhgIx3np5AhDo3GW1VWwsb2aB57q5rWzId69pY03X9k8Hs9PD5ylwuvi5FCEhkoPZW4XPreTHasbiafSHOoNs6y+nIy1vN4/yoGeAMf6wqxrq6a2wsu61io66ssv+l7FU2kOnAnSWOklkcpwuDdEfzjBDavr6az3AxBJpHj8YD89gRjXLK9jfXv1hPdsVaOf6nL3hPOGYsnx+Br83rznzWSy/0ZlHiermvwXjfFIX4hYMsO61iocDnPRx4rIzL336z/jhdNRALrvvaPE0chis+twP72BGHduasXnyU9FOu95EIBP37SET9++ea7Dk0UsGEtyuDdMZ3059ZPkNJdStMQauBbYmdveCWwHxhLrOmvtSQBjTPVF9l3SiydHePxgP2CJJtKUeVy8dHKYSDxNKmM5MxLlzk1tE475wQunCMVSdA+M0tlQgdft4Nd3rODh/Wc51j+Ky2H41R3LKc/9z949EOZr/3GIjLUc6QtT5XMTiCZ5tSfA8cEoHpehudJHZ2MFyZSlvbaMdMby6ME+Hn21j6HRBCub/FSXufnpgV5iyTQvHB+iptzD1mW13PfIIV4+GeDkcASnAazBX+aiuSqb7I9Ek/QF43hcDqy17D4+zJ7jw6TSGdx7e1jZ6OdNnXX8+o0rJk1sxzz6Wj+v9gQJx1MY4LGDfbicDp44PMDXP3wVbqeDf3nxNN959gSBaJLnXh/i925fy/KGivH37JVTI3zs+uUTzvvDl8/QF4xT5nFy944VeQnx891DPHV0EID3X72EpXWT/wHQPTDKj17uASCWTNPVWTfVy0BEpmksqQZYdc+DHFFyLXNk76kR/vxnRwAYCCf4jZtXTmgfS6oB/vTxU0qsZU79KJfTPH+BnOZSijkUpAYI5rYDQO0FntdxkX0TGGPuNsbsNsbs7u/vB7I91tlbSGc3yWQsuU3SGZt3nkzumPQ5x479AFje2M4+nvHznXvusf3WZrvZsTDWms5YMplce+4nbTPj57TnxJbJTIzLYsfjyeR+zn1ua+3468aO3X/j+At5470ae56xU9jx15vJ5M6dO+94jHbsNv+84/Fd4PnPPeZiMZ7bNtm/m4gUh/5vk7l07ud7KpO5yCNF5t6lcppLKWaP9QhQlduuyt0fk5lke7J9E1hr7wfuB+jq6rIAVy2txelw4HYaGiu9vN4/ypqWSkKx7HCNDe1Veed579YlHO0L896t7ZwNxOioL8fjcvDW9c3sO50dClLhfeOtWdHo57duWcWxgTDv3txOMJakJxDj3Ve18/TRAbwuBxtzQyaMMbidDta3VdFc5WNVUwUDoTidDX6uWlrDstpjvNoT5N1XtbNtebZH9pO3ruIn+85S5nZyajhCvd+D3+uizOPiljVNxJMZXjsbZHlDBWlr2bK0hm2dw3QPRrmyxU9jpY/17dU0Vfou+g9yy9omGiq9NPq9JNIZNrRXMxiOc+MVjXhc2b9l7tq6BL/PxZnhKNetahgfujH2nq1ursw777s2tY3HN9lfdts6a/G6HZR7nCyrr7hgfCsa/bx9QwuxZJpNS2ou+lpEZHaW1To4Ppz9qD2q3mqZQ1d11PLrO5bTG4pz11Xtee3d994x3mv9kaub5jo8WeQuldNcirEzzMgveWJj3gr8PVAJfBP4prX2uVzbTt5IukettbdMtu9i5+/q6rK7d+8uSuwis9HV1cW51+a5X2vOhMa/Lm6Fvn7Ovz5F5gtdmzKfGWP2WGu7Lvm4IibWPuBPgQ+RTbA/D/yqtfYLxphHyCbcBgjnEuu8fRc7f0NDg+3s7Jywz1pIpjO4XQ4u92lv46/V6cBc4sWmct9ruKbwl1cincFpDM7zHptMW4yZ/ByJVAaX0+C4VCCzcP6/bSKVwekwpDN2/D1IZ94YuuJyOrjQy02lLVzgtVxIxpId037etZWxllTajvf4A3R3dzN2babSlngqTbnHdcl/J5FCymQyHO0fpdLnouWcydjnXp8i88m51+ZAOE4ilaGtpuziB4kUWCKVpjcYp67CM2H0wp49e6y19pJDqIs2FMRaGwN+wxizFviUtTYFfGHsea21bwIwxjx2kX0X1NnZmfeX7d893c1gOEFHXTnvu3pJQV7HfPWPu09yejhKY6WXX9q+7IKPO9Yf5ocvnwHgPVva6Wy48FCMp48O8syxQTwuB//p2mVU+bLVPw71hnhwbw/GZCcfLql9Y/Lho6/18dLJEco8Tj52XWdeBZZCyGQsDzzdzUgkyYrGCrwuB6/2hDjaH6azvoKWah/v3NzGt585zr7TASo8Lq5sq+Jj13Xm/YFwpC/Mj14+gzFw11XtFx2aMiadsfztU90Eo0lWN/vHJ8Mm0xkeeKqbUCzF2pZKbt/YCrzR6xKOpfjU914kHE9x9bJa/t+3ry34eyNyIat+/0Fqc4PqfvktK/nkrdnrT72CMl+NXZt/+h8Hue/RI3gsNLRU8tCnbyx1aLKIrP2jn1CWzJB0GJ78zK14vdmiEMaYF6ZyfKkWiCnY5MUxmYxlJJIEYDiSKGCo89NI7jWORBJc7FuH4UhyfCLkpd6XsfZEKkM4lnpj/2h2v7WMv8djhnJt0USaWDI9/RcyBamMJRhNjccyNJqNYSSSJJ2xjEQShGJJEqkMsWSaaDJNKJYkmc4fqj/2vmXfj2Re+2SS6QyhWHL8+c/dH45n4xqa5L0NxZLj7b3B2FRfrkhBpM65/J8+NlS6QESmaV9PcHxCfX9Yn50yt5K5D8+0tQTj0z++mJMXL6ZgkxfHOByGd2xs4eDZMJuWTLla34L1tvUt7DsdZG1rJeYiYww2tlcTjGaTwg3tF39frl/VgMNAvd874eu3LR01hOMpXE4Ha1smTl68eU0jz74+RFtNGTXlnlm8ogvzuBy8fUMLR/rCbOmoweUw7O4eZkN7FYmUZW1rJUtqy7luZT0t1V7cDifr2/PrlwNsWlJDMJbEGMP6tvyJrZPxuZ28bX0Lx/pH2brsjUmV5R4Xb1nXTPdAhK7O2rzjWmvK+NC2DvadCfC+q/Mn6IgU00e3L+Vbz5zE4zR859evK3U4IlP2Fx/axC1ffYLReIovvlfrxcncumtrGw/t62NrRw2NVdOvY120MdbjT5Ad1nFbbijI2L5/AT5JNoH+hrX23ZPtu9h5NXlR5it91S7zma5Pma90bcp8NtXJi8VcedEN/ATYDDxsjPkccIO19gvAZ4DvkZ2o+Ju5QybbJyIiRaSqNSIihVPMyYtJ4Lbzdj+ea9sL3HDe4/P2iYiIiIgsFKWavCgiIiIicllRYi0iIiIiUgBKrEVERERECkCJtYiIiIhIASixFhEREREpACXWIiIiIiIFoMT6/7Z353FyVXX+/1+frq7e93RnIxsJIWELEJolSEAWlxmHr4P7MuqgP1G/81UccPzxHVRQwcGVARxQdBQXHMUlCqIoEQIhEMhCEiAQQvaQrZPe96U+3z/u7U6l00slXZWqgvfz8ahH3Xvuvac+t/p096dOnXuuiIiIiEgSKLEWEREREUmChBJrM1tpZv9iZpWpDkhEREREJBsl2mP9PmAysMLMfmlmbzEzS2FcIiIiIiJZJaHE2t1fcffrgROBXwA/Arab2ZfNrCqVAYqIiIiIZIOEx1ib2Tzg28A3gd8C7wKagUdSE5qIiIiISPbITWQnM1sFNAL/DVzn7l3hpqfN7A2pCk5EREREJFsklFgD73b3zUNtcPd3JDEeEREREZGsNGJibWbXxC0ftt3dv5OCmEREREREss5oPdal4fMc4Gzg/nD9cuDxVAUlIiIiIpJtRkys3f3LAGb2V2C+u7eE6zcCv055dCIiIiIiWSLRWUGmAd1x693AjKRHIyIiIiKSpRK9ePFnwDNmtghw4Argp6MdZGa3ArXAane/Oq78l8BEIB8odPczwl7wK4AG4H6N3xYRERGRbJJQYu3uN5vZQ8AFYdGV7v7sSMeY2Xyg2N0XmtldZna2u68I63tfuM8VwFlxh13r7ouP+CxERERERNIs4RvEAGsIxlUvAg6Y2bRR9l8A9CfJi4HzhtjnCuB3cetfN7PFZnbGEcQlIiIiIpJ2CSXWZvZpYC/wMPBH4MHweSQVBHdmBGgCKgfVmQuc5u6rw6Lb3f0s4FPAHcPEcZWZrTSzlXV1dYmELiIiIiJyTCQ6xvpqYI67HziCuhuBsnC5LFyPdzGwpH/F3evD541DzZkdbrsbuBugtgxjYG8AACAASURBVLbWjyAWEREREZGUSnQoyA6CXucj8RRwabh8GbB80PYrCIaVAGBmZeFzNYkn/CIiIiIiGSHRBHYzsMTMHgS6+gtHmrnD3VebWaeZLQXWAtvN7PrwQkgjGIP9f+IO+aaZnUqQ7F93pCciIiIiIpJOiSbW28NHXvhISPwUe6Gbw3IHzhy07ycSrVdEREREJNMkOt1e/x0YS4NVb01pVCIiIiIiWSbRWUFONbNngeeBF8xslZmdktrQRERERESyR6IXL94NXOPu0919OnAt8IPUhSUiIiIikl0STayL3f3R/hV3XwIUpyQiEREREZEslPCsIGb2ReBn4fo/AVtSE5KIiIiISPZJtMf6o0ANwe3HF4XLV6YqKBERERGRbJPorCANwGdSHIuIiIiISNZKKLE2s1rg34EZ8ce4+7zUhCUiIiIikl0SHWN9L/BvwHNALHXhiIiIiIhkp0QT6zp3vz+lkYiIiIiIZLFEE+sbzOyHwN+Arv5Cd/9dSqISEREREckyiSbWVwJzgSgHh4I4wSwhIiIiIiKve4km1qe7+2kpjUREREREJIslOo/1cjM7OaWRiIiIiIhksUR7rC8APmJmWwjGWBvgmm5PRERERCSQaGL91pRGISIiIiKS5UZMrM2sKlxsOQaxiIiIiIhkrdF6rFcRzP5hQ2xzYGbSIxIRERERyUIjJtbufvxYKjezW4FaYLW7Xx1Xfg9wEtAB3O3uvzCzycDPgQLgS+6+eCyvLSIiIiJyLCU6xhozqwRmEyS+ALj74yPsPx8odveFZnaXmZ3t7ividvmgu78St34d8AVgHfBHQIm1iIiIiGSNhKbbM7P/D3gc+Avw5fD5xlEOW8DB5HgxcF7cNgd+amYPmNn0sGwe8JS7twItZlaa0BmIiIiIiGSAROexvho4G9jm7hcDZwJ1oxxTATSHy01AZdy2a939fODrwLfDsoi7+zD7A2BmV5nZSjNbWVc32suLiIiIiBw7iSbWne7eCWBm+e7+EjBnlGMagbJwuSxcB8Dd68PnJ4CJYXFf3LGH7B933N3uXuvutTU1NQmGLiIiIiKSeokm1jvNrAL4PfCwmf0B2DXKMU8Bl4bLlwHL+zeYWVn4PIeDCfQ6M1tgZsVAmbs3IyIiIiKSJRK6eNHdrwgXbzSzR4Fy4KFRjlltZp1mthRYC2w3s+vd/Wbg3vBiSAc+FR7yDeCnQCFww5GfioiIiIhI+iSUWJvZt4Afuft6d38s0crjp9gL3RyWXz7EvjuBSxKtW0REREQkkyQ6FOQl4Adm9rSZfdLMylMZlIiIiIhItkkosXb3H7r7G4APAzMIxkP/wswuTmVwIiIiIiLZItEea8wsAswNH/sJxk1fY2a/TFFsIiIiIiJZI9Ex1t8BLgceAb7m7s+Em75uZhtSFZyIiIiISLZI9JbmzwNfcPf2Ibadk8R4RERERESyUqJDQT44OKk2s78BuHtT0qMSEREREckyI/ZYm1kBUARUh/NOW7ipDJic4thERERERLLGaENBPgF8liCJXh1X3gz8V6qCEhERERHJNiMm1u5+G3CbmX3a3e84RjGJiIiIiGSdRC9ebDKzDw8udPefJjkeEREREZGslGhifXbccgFwKcHQECXWIiIiIiIkmFi7+6fj18Nbmv8sJRGJiIiIiGShhO+8OEg7MDuZgYiIiIiIZLNE77z4AODhag5wMnBfqoISEREREck2iY6x/lbcci+wzd13piAeEREREZGslOgY68dSHYiIiIiISDZLaIy1mb3DzDaaWZOZNZtZi5k1pzo4EREREZFskehQkG8Al7v7i6kMRkREREQkWyU6K8jeo0mqzexWM1tqZrcNKv++mS0zsyfMbF5YdqOZrTWzJWZ2zZG+loiIiIhIOiXaY73SzH4F/B7o6i90998Nd4CZzQeK3X2hmd1lZme7+4pw8y3uvsXMZgO3AO8My69198VHfhoiIiIiIumVaGJdRjB39ZvjyhwYNrEGFgD9SfJi4DxgBYC7bwnLe4C+uGO+bmYNwOfcfU2CsYmIiIiIpF2is4JceRR1VwCbwuUm4JQh9vkP4PZw+XZ3vzHsxf4RsHDwzmZ2FXAVwLRp044iJBERERGR1Ej0BjEFwMcIkuOC/nJ3/+gIhzUS9HQTPjcOqvOzwHp3fyKsqz583mhmQ1bo7ncDdwPU1tb6kDuJiIiIiKRBohcv/gyYCLwFeAyYArSMcsxTwKXh8mXA8v4NZvZm4HzgpriysvC5msSHqIiIiIiIZIREE+sT3P2LQJu7/wR4G3DaSAe4+2qg08yWAjFgu5ldH26+AzgeeNTMvh+WfdPMlgEPANcd4XmIiIiIiKRVoj3DPeFzo5mdCuwBZox2kLtfPajo5rB8zhD7fiLBWEREREREMk6iifXdZlYJfBG4HygBvpSyqEREREREskyis4L8MFx8DJiZunBERERERLJTQmOszWyCmf23mf05XD/ZzD6W2tBERERERLJHokNB7gF+DPRffPgy8Cvgv1MQk4iIiGS4Gdc9OKbjt97ytiRFIpI5Ep0VpNrd7yOY3QN37+XQOyaKiIiIiLyuJZpYt5nZOILbmGNm5xHcTVFEREREREh8KMg1BLOBzAznmq4B3pWyqEREREREskyiifV6YBHQTnDHxd8TjLMWERERERESHwryU2Au8DWCuybOJrjNuYiIiIiIkHiP9Rx3Pz1u/VEzW5uKgEREREREslGiPdbPhhcsAmBm5wLLUhOSiIiIiEj2SbTH+lzgw2a2PVyfBrxoZs8B7u7zUhKdiIiIiEiWSDSxfmtKoxARERERyXIJJdbuvi3VgYiIiIiIZLNEx1iLiIiIiMgIlFiLiIiIiCSBEmsRERERkSRQYi0iIiIikgQpTazN7FYzW2pmtw0qP9XMnjCzZWY2b7gyEREREZFskeh0e0fMzOYDxe6+0MzuMrOz3X1FuPmrwPuBGHAn8PZhykbV3t3Loy/VkZebwxvn1BCNBJ8VVmytZ2dDOwtmVjOxvOCQY17a08z6Xc1Ul+Szv7WLWTUlnD61gt1NHSzffICplUXUzqga2N/d+cHSzeyo7+BD502nubOH7fXtuMOD616ltSvGWdMrOHFCKWZQEM3l4rk1bNzbygNrX2XtjiZOGF/CJXNr+PpDG2jq6OHy0yfz+bfMJZqbw9odjdy3cgd9fU5daxdlhbm0dfUSycnh2jefSCQnh2e3N3DihFK6e/u4b+VONu1roSAvl2lVhZQVRJlaWUR+NId5UyrojTmrttWzflczJQVRPnHhTMaV5FPX0sWyV/ZTU5JPd1+MZZv209jezZtOmshbTp0IwI76dr76x/W8vLeFc2dW8a9vms0zWxrZUd/Gqw0dzJ9WybtqpwLQ0d3Hoxv2caC1i4JohFk1Jexr6QSMi+fW0NHdx2Mv15GfG6Gnr4+ivFwunF3Dsk37ae7s5aLZNbT39LJ88wHc4Zkt9Ww90MbUqiLmHVfO/OmVnDK5POE2139+48vyOX9W9ZD7uDvLXjnAgbYuLjihmnEl+aPW29jezWMv11FZlMfC2dWYWcIxzbjuwYHlrbe8LeHjRMZq/pcfor6jD1Dbk+xy5+NP8Y0/1Q+sq/3KsXTOV//KvrYeCnNzePGmvzvi41OWWAMLgMXh8mLgPKA/sa5y9x0AZlY+Qtmo1mxv5OW9LQBMKi/g1OPKaWjr5omN+wHo6avjPWEi2O/hF/bSG3P+9NxuTplczvb6duZMLOXxl+vY1djJ1v3tzB5fSnlRFIAXXm3iby/uA+BHy7YwoayApo4e1u1sZFNdK+6wvb6NBTPHEQNmjCumqjjK4y/v56EX9tLQ1s3upk6e3LSfnQ0d9Mac+9fs4vxZ1Vw8dzw/X76Nl/e2sO1AO3kRo7svhjuUFOTykye3Mn1cMS2dvWyua+NAWxdPvLKf+tYucnKMl/e2MLGsgEhOPadPqWBPcyd9MVi3o5ENe1uYXFHIH9a8ykcvmMmyV/azZX8bq7Y1EMmBJRuCDyT7W7u5aE4NBdEIP1++jeWbD9DZ08cjL+6jJD+XkvwoD67bRVFeLtsOtHPhnBrGlxbw7I4GNuxpYfX2BqZUFLJiaz0TSgvIyTHGl+Wzr7mLzXVtbD3QRmVRlPLCPMyMtTsaASiMRqhv62JXYyePbthHY3s3DW3dbKlrY39LF/VtPcydWEYkJ7FE9slNwflt2d/GrJoSJpQVHLbP7qZOVmwN/mBHcox/mDd51HqXbz7A5ro2oI0Z44qZNq4ooXjmxCXVIsdaf1INMPcLD/LSTUpOJDvEJ9Uix9q+th4AOnpjrN/ZzMlTyo7o+FQOBakAmsPlJqBymNfNGaHsEGZ2lZmtNLOVdXV1AIwvy8csSJJqSoPex6L8CKUFwWeGoZKr/rIplUGCVFWcR14kZ6C8rDBKYV5kYP+J5YUUheuzaoopK4xSEM1hYlkBeZEcohGjvDBKaWEupflRcsyYWFbAhLJ8ygtyyY3YQI9uJMcwC/afHiZo08YVkRsxSvJzyY3kUJSXS340Qm5OziEJ4oSyfCaXF1AUjRCN5JAXyaE4L0JBNMK4knzyozlMLCtkfGk+FUVRCqIRcnKM46tLDjnv6pI8ygujFOfnkhc5eB4As8eXUBDNwTCK8yKcPCloUJXFeeRGjKriPErzowP1mUFZQZSi/AhTKgvJjeSQY0ZNST4TyvLDY4NYohFjxrgi8nJzBs6nP6ZJ5QUURnOIRHIoyotQWZRHTWl+wkk1wPjSoK6ivAhlBdEh9ymP+9kO1TaGrDfcLz+aQ0Xx0PUO5c0nVY6+k8gxcP7MqtF3EhGRQxxpUg1g7p6CUMDM/gWoc/f7zOwdwBR3vz3c9pi7XxQuL3H3Nw5VNlL9tbW1vnLlSgAa2rqJROyQZKqzp4+mjh7Gl+Yf9tV9T1+MA63dVBVFaejooaIoSn5uBHdnX0sX5YVBIhivvq2LPU2dnDy5fKDu4rwI2+vbaGjvZe7EUiBI8A2jvChKd2+MPc0d7GnsYHx5AdMqi3n85TqaO3s45/gqJpYXAtAXczbsaaa8KEpdSzflhbl0dvfR0+fMm1pBX8ypa+miqjgPx9lR305jew/5uTmUFuaSY0ZFYZT27hjVJXk4cKC1m46eXgxjRnXxwHnsa+6ktCBKnzuN7d00tvcwq6aYwrzgg4i789LuFrYeaOW04yqYUlXE/tYuIjnGqw0dTK8qorTw4Pvc0NaNA929MaqK82jv7h04fwiGZxTlRejs6SMvN4fSgiitXb109vRRXZJ/8D0vyGXrgXY6e2OUFeZSFM1lXEnewNCeRPWfX/wHo8Hau3tp7eodSMQT0X8exfmjf8lTW1tLf9t867f/ykt1Pdz/ganMm6dLB+TYmnfDn6idXsmPPrpgoCy+fcKhw5WOhr6mf/1KdtuJb5szr3uQ2BD7iKTa+p3N/Ntvn+Wzl8ziTadNGSg3s1XuXjva8alMrN8M3AuUAj8Gfuzuz4TbFgP9HwPa3P3iocpGqr+6utpnzJiRkthFxmLr1q2obUqmUvuUTKW2KZls1apV7u6j9valcoz148BvgfcRXJC43cyud/ebgf4u5Piu5KHKhjVjxoxDel2yQWN7N+t2Nh3RON3h7Gvp5KXdLcyeUMKk8kL2NHXy8t4W5kwsHRjisH5XMwdau7AcKMiNMH9aJTkjDK3o6O5j9fYGqorzOCkcAtLV28czW+p5taGD2RNKmT+tYuAbgN6+GEs31rHlQDsXnlDN8TUlrN7egAHzp1XS3Rdj9bYGyouih1yE+PyrTTR39HDWjErycyMD782z2xto6uylvCDohT9hQinHVRQeFmdTew9rdzYyrarokN749u5eVm9rZHxZPidOKB3yHPtizqJnd9Lc0ct7a6dSXDD6r0BnTx+rtjVQMeg8hhPf67Jlfxs76ts5fWoF5YWJDyMRGavP37eK+1bvIQfYHNfr198+v/3Qi3x3yWbKC3JZc+Nb0heovC794389wb7mLu784JmcMS0YqjT42xSRTGJmqxPZL2WJtbt3Ap80s7nA1e7eC9zc/7rufg4Ewz5GKHtNeej5Pexu6mTtjkY+fuHMw4abHIkH1u6muaOH53c18amLZvH7Na/S0d3Hhj0tfPzCmexp6uQvL+xhb3MnbV29zKwpIT83wmlThk8MH99Yx/pdwbD4ccV5jC8rYPnmeh5ct4ttB9o5aVIZRXmRgaR7zY5GfrliB43tPWyua+Wtp05ixZbgopP83Ah1rZ2s3dEEQGVRHpMrCtlR387D6/cC0NUX4+I54wfem5Vb69nZ2EE0J4cZ1UU8v6uZT10067APA395YQ+vNnawZkcjH184c2DYx5INdWzY04JZEP9QM3489vI+fr1yJwC9fc5VF80c9b1e9sp+1u0MzqOqOI9J5Ycn+0Np6+rl/jW7iIXDXd511pTRDxJJkvtW7wGCXo2LvvE3Hvv8pYdsv2PJZgAaO3v5xE+e4fsfOedYhyivU9f9Zi1rwv8NH/vpSlZ94c1pjkgkedJ1g5ikXbyYTfKjwWnlRnKO6KK8IesKLwDMz41gZgfXw9eIRowcMyI5NvBa/dtGqzPHbGBsc37uwVgjca/T/9q5OQfjKIr7oJAfzRnojR5cX/+Q90PqCi9cjJiRGzEiOTmH7HtInAPvo5ETd0r99QV1DH2uxXm5A3UWFyT2wWao80hEJCc4l/jYRNKhpjhvxO2TE/ywKJIM40ryDv4fiBx9B5NIJkrZGOuBFwh6ny8Le6z7y5J68WK26Ozp45V9rRxXUUjlKP/oRtPW1cuW/W1MG1dEWUGUls4eth1oZ0Z1MSXhBXa7mzpobO8JErwcY2ZNyYh19sWcl/e2UFmUNzD3dyzmbNzXyv7WLo6rKDxk6AXAS7ub2NnQwelTK6kpzWdTXSs5ZhxfXUws5ry8r4WygiiT44Z0vNrYQUtnDyeOLx3ojQ7emxY6e2KU5kfpicWYWlU05PCJrt4+Nu5tZXJFIVVx72NvX4yX97ZSXZI3MJPHUJ7efICWzl4unjs+oQ84sZizYW8LFUXRhHqr47/OPNDaxe6mTmZPKBlI0EWOhYdf2MVVP3uWmpIoz8T1CPa3z1Xb9vOh/17BnPElLPo/C9MYqbweXf+759hU18rdH5xPWfjtooaCSCZL+8WLcYEs4fDEehHwaYJvKe9y97cPVTZSvdmYWMvrg/45SCZT+5RMpbYpmSzRxDqVd16MAn8GTgf+YmZfAS4IL168AfglwYWK/xIeMlSZiIiIvA5pKkjJRqm8eLEHuGxQ8WPhtnXABYP2P6xMRERERCRb6IoqEREREZEkUGItIiIiIpIESqxFRERERJJAibWIiIiISBIosRYRERERSQIl1iIiIiIiSaDEWkREREQkCZRYi4iIiIgkgRJrEREREZEkUGItIiIiIpIESqxFRERERJJAibWIiIiISBIosRYRERERSQIl1iIiIiIiSaDEWkREREQkCZRYi4iIiIgkgRJrEREREZEkUGItIiIiIpIEKU2szexWM1tqZrcNKv+lmS0xs6fMbE1YdqOZrQ3Lr0llXCIiIiIiyZabqorNbD5Q7O4LzewuMzvb3VcAuPv7wn2uAM6KO+xad1+cqphERERERFIllT3WC4D+JHkxcN4Q+1wB/C5u/etmttjMzkhhXCIiIiIiSZfKxLoCaA6Xm4DK+I1mlguc5u6rw6Lb3f0s4FPAHUNVaGZXmdlKM1tZV1eXorBFRERERI5cKhPrRqAsXC4L1+NdDCzpX3H3+vB543AVuvvd7l7r7rU1NTXJjVZEREREZAxSmVg/BVwaLl8GLB+0/QpgUf+KmZWFz9WkcOy3iIiIiEgqpCyxDod4dJrZUiAGbDez6wHMzAjGYD8Rd8g3zWwZ8ABwXariEhERERFJhZT2DLv71YOKbg7LHThz0L6fSGUsIiIiIiKppBvEiIiIiIgkgRJrEREREZEkUGItIiIiIpIESqxFRERERJJAibWIiIiISBIosRYRERERSQIl1iIiIiIiSaDEWkREREQkCZRYi4iIiIgkgRJrEREREZEkUGItIiIiIpIESqxFRERERJJAibWIiIiISBIosRYRERERSYJRE2szi5jZvx6LYEREREREstWoibW79wFvPwaxiIiIiIhkrdwE91tmZt8FfgW09Re6++qURCUiIiIikmUSTazPD5+/ElfmwCXJDUdEREREJDsllFi7+8VHU7mZ3QrUAqvd/eq48nuAk4AO4G53/4WZTQZ+DhQAX3L3xUfzmiIiIiIi6ZBojzVm9jbgFILEFwB3/8oI+88Hit19oZndZWZnu/uKuF0+6O6vxK1fB3wBWAf8EVBiLSIiIiJZI6Hp9szse8B7gU8DBrwbmD7KYQs4mBwvBs6L2+bAT83sATPrr2ce8JS7twItZlaa2CmIiIiIiKRfovNYn+/uHwYa3P3LBEnz1FGOqQCaw+UmoDJu27Xufj7wdeDbYVnE3X2Y/QEws6vMbKWZrayrq0swdBERERGR1Es0se4In9vDsdA9wPGjHNMIlIXLZeE6AO5eHz4/AUwMi/vijj1k/7jj7nb3WnevrampSTB0EREREZHUSzSx/qOZVQDfAFYBW4FfjnLMU8Cl4fJlwPL+DWZWFj7P4WACvc7MFphZMVDm7s2IiIiIiGSJRC9e/BbwKWAhQcK8FLhrpAPcfbWZdZrZUmAtsN3Mrnf3m4F7zaySYKz1p8JDvgH8FCgEbjjiMxERERERSaNEE+ufAC3A7eH6+wmS4PeMdFD8FHuhm8Pyy4fYdyeaF1tEREREslSiifUcdz89bv1RM1ubioBERERERLJRomOsnzWzgenyzOxcYFlqQhIRERERyT4j9lib2XME46CjwIfNbHu4Ph1Yn/rwRERERESyw2hDQf7hmEQhIiIiIpLlRkys3X3bsQpERERERCSbJTrGWkRERERERqDEWkREREQkCZRYi4iIiIgkgRJrEREREZEkUGItIiIiIpIESqxFRERERJJAibWIiIiISBIosRYRERERSQIl1iIiIiIiSaDEWkREREQkCUa8pbmIiIiISLaZcd2DYzp+6y1vO6rj1GMtIiIiIpIESqxFRERERJIgpYm1md1qZkvN7LZB5d83s2Vm9oSZzQvLbjSztWa2xMyuSWVcIiIiIiLJlrLE2szmA8XuvhDIM7Oz4zbf4u5vAK4Ebogrv9bd3+ju30lVXCIiIiIiqZDKHusFwOJweTFwXv8Gd98SLvYAfXHHfN3MFpvZGSmMS0REREQk6VKZWFcAzeFyE1A5xD7/AdweLt/u7mcBnwLuGKpCM7vKzFaa2cq6urpkxysiIiIictRSmVg3AmXhclm4PsDMPgusd/cnANy9PnzeOFyF7n63u9e6e21NTU1qohYREREROQqpTKyfAi4Nly8DlvdvMLM3A+cDN8WVlYXP1Wh+bRERERHJMilLrN19NdBpZkuBGLDdzK4PN98BHA88ambfD8u+aWbLgAeA61IVl4iIiIhIKqS0Z9jdrx5UdHNYPmeIfT+RylhERERERFJJN4gREREREUkCJdYiIiIiIkmgxFpEREREJAmUWIuIiIiIJIESaxERERGRJFBiLSIiIiKSBEqsRURERESSQIm1iIiIiEgSKLEWEREREUkCJdYiIiIiIkmgxFpEREREJAmUWIuIiIiIJIESaxERERGRJFBiLSIiIiKSBEqsRURERESSQIm1iIiIiEgSKLEWEREREUmClCbWZnarmS01s9sGlZ9qZk+Y2TIzmzdcmYiIiIhItkhZYm1m84Fid18I5JnZ2XGbvwq8H3hPuDxcWULcfdTl4Y4ZvM9Ix/T1xYY8vq+vb2C5/xG/XywWGyjr64vR29t7WN2xWGzgub+O/rKhzisWix2y71DnN1R5LHZ4PUMd29vbe9jx8ec/1DEjOZKfxXD7Dneeg9dHi+VoHUlc8dauXZuKcERG1dDQMOL2p5566hhFInK4rq6udIcgknS5Kax7AbA4XF4MnAesCNer3H0HgJmVj1A2qj1Nnfzu2Z3kRXKoLMpjR0M786dWsrelk12NnVw8t4Z5UyoOOWbx+r08v6uJgtwcOntjzKwp4fJ5k1i3s4klG+o4rrKQK848jkiOAdDW2cMXfv8Ce5s7+cC50+jsjbHtQBvNHT08umEfXb0xjq8u5sypFWBGZVGUd86fwvLNB7j36e1sqmtlamUh7zjzOL776CYa2ns47bhS7vxgLdWl+fxm5U5+vWoHLZ29tHf3kp+bQ1dvjGgkh397y4mU5Ed5Zms9s8eX0NLVy/88vZ1djR1EI0ZNWQGVRXlcdGIN7z9nGgXRCH99YQ9PbTpAS1cvp0wu4z21UynOz+XF3c08vH4v5YW59PTGeGRDHe3dfSycXc01bzoRM+OJjXVcv+h56lq6mFVTxHc/eBbTxxXz4ye28Nf1e5gzqYzr//4kopGDn8mefGU/z2ytZ86EUv7utEmH/Yx21Ldz/9pdFEYjvOfsqZTkH2x2a3c0smRDHUV5OTR19PDy3lZOmlTKe86exnEVhQP7/XHdLl7Z18q5x49jwaxxACzZsI81Oxo5eVIZF55Yw69X7eT5V5vIz83hrOmV/K/TJ2NmiTalYbk7D6zbzea6Vs6fVc05x1cNlP9hzS62Hmhj4exqzppedchxP125li/9Zmew8j872XrL28Yci0iiTrz+QbqDz/zc+s6TuOLsmYdsn3Hdg8HCHx7k3Gl5/Op/v+kYRyivV09urOPDP15BzJ03nzyB732oNt0hiSRNKoeCVADN4XITUDnM6+aMUHYIM7vKzFaa2cq6ujoAXtnXSldPjOaOHlZsrccdVm2rZ2dDBzF3XtzdfFg9L+xqxh2e2dqAO2za10pnT4z1u5uJubOjvp3mjp6B/TfWtbGrqYM+dx57ed/A9nU7m2jq6KGju4+t+9vYiTE+iAAAEkRJREFU1djBqw0dtHX1sXFfC+t3NbOzoZ2O7j7qWrr5w9rdNHf20BeLsb2+gzU7GgF4cvN+Onv62NXYTltXL3uaOmlo66a9u5fHNuwfiHf9rmae3dbAgdYu2rp6ae7sZU9jJ/Vt3Ww/0E5dSxfuzvrdzexv7WJ3YweN7T3sauwA4MXdzfTFnFf2tbKjPoi1vauXdTub6OwJeqOXbNhHQ3s3vbEYe5q7eGZLPQDLt9QTc3h5Twv1bd1Dvp8v7Wmhd4he7Vf2tdLdG6Opo4edDe2HbOt/z5/f1cyupk6aOnqoa+lm496WgX26evvYuLc1eA/ifp7rdwev++LuFvY2d7K/pYs9TR3sb+lic13bwDmNVWdPjE37wtff1TRQ3tbdx5b9bQM/m8Fu7E+qRdKgP6kG+MZfN42479Pbu0fcLpJMP3pyK70xJ+bw5KYD6Q5HJKlSmVg3AmXhclm43i82xPJQZYdw97vdvdbda2tqagCYO6mU8sIo48sKuGhODQXRCOfPrmb2hBIK8yKcMbXysHrOml5JQTTCJXPHU5gX4dTjysN9KyjMi3DihKDOfidNLOWE8SUU50V422mTOHFCKePLCnjDCeOYUFZAeWGUU44r54TxJcyeUMK4kjxOmlTOWTMqmTOhlIqiKNOqCvmn86YxvrSA/NwcTppUOtDzeenc8VQWR5k9oZRxJfkcX13MpIpCqorzeMupE5g/vYKCaITaGVVcMLuGqVVFVBblUVOSz8yaYqZWFjJ3UikTywswM+ZPq2RKVRGzakqYVF7A1KoiAE6fWkFRXoR5UyqYO7mU2eODWM+fNY7CvAgAbz1tEpPKCyiIRphVU8wFs6sHYizMizB/WiXVJfmHvJ/98Z0xtYLcyOFN6qRJZZQW5DKxvIDpVcWHbOt/z889vooTakqYVF7ItKpCTp5UNrBPfm6EeVPKKYhGOHPawW8f5k8Lfo7zp1cwuaKQqVVFzKwuYdq4Ik6ZXDZwTmMV30bOnHawPRXnRThpUtlh5f0WvX9KUl5f5GiURA/+Ln7zPSNftvJPZ1eNuF0kmf710hPJixgRg78/dWK6wxFJKkvVeNRwjPUn3P0TZnYncI+7PxNuWwR8miCBvsvd3z5U2Uj119bW+sqVK1MSu8hY1NbWorYpmUrtUzLV4LY5MFzpKGn43etbstuPma1y91HHLaUssQ6DuA2YD6wFbgI+5u43h7N+3AkY8C/uvmaoslHqrgO2pSz4Y6Ma2J/uIJJI5xOYD6xOQj3HiuIbm2yLT+0zeTI5Nsi++NQ2k0vxjc3g+Ka7e81oB6U0sZaRmdnKRD79ZAudT2rrSRXFNzbZHl+2x59OmRwbZH982R5/uim+sTna+HSDGBERERGRJFBiLSIiIiKSBEqs0+vudAeQZDqf1NaTKopvbLI9vmyPP50yOTbI/viyPf50U3xjc1TxaYy1iIiIiEgSqMdaRERERCQJlFiLiIiIiCSBEmsRERERkSRQYi0iGcfMis1sipmVpDsWkXhqm5LJ1D7TTxcvHkNmdhZwHlAJNALL3T1r7y2s8xmyjlMJ7jJaRvDB1cO6bnD3dcmN+MiZ2Wfd/T/N7HTgDoL4coHr3H1peqMDM7sE+CLQHD7KgFLga+6+OJ2xQVa8fyO2P7XPMcWmtjlGI7U/IDbcNrXN0al9jk1S/za6ux7H4AHcSnDL9ncAlwJXAP8F3J7u2HQ+yTsfYCkwaVDZZGBpus8xjOWR8PmvwAnhcjWwLN2xhbE8ARQNKivOoPgy/f0bsf2pfY4pNrXNscc4bPtT2xxzfGqfY4svae0vFzlWznL3CweVLTKzx9MSzdjpfIZno6ynU1XYs1Hl7q8AuPt+M8uUr666gNOAp+PKTgM60xPOYTL9/YPR25/a59FR20yOkdqf2ubRU/scu6S0PyXWx85KM/sesJiDX9NcCqxOa1RHT+cztE8C3zWzKoKvk2LAAeB/JzHWsVgELAQeMLMKd280s1Lg+TTH1e+fgOvM7BYgAvQBa4EPpzWqgzL9/Rut/al9Hj21zbEbqf3FRtiWCTL9/VX7HJuk/W3UGOtjyMzOJBjDW0Ewdqfa3b+a3qiOjplNAiYCC4Bygk92MeBb7t6bztiOhpnlAdcRjKvqBaLh8h3u3pjO2ERERCQ7aFaQY8TMlgK3AR8A/j58/mwWD524192fBeYSJNYrCRLrX6Q1qqP3K4KEuhS4DGgDtoflCTOzU83s92b2iJktCZ8Xmdm85Id85ML4fmNmvzSz8+PK70pnXP3M7H3h81Qz+7WZPW5m95vZyemODcDMVpvZV8zsjHTHMpTR2p/a59FT2xy7kdqf2ubYqH2OTVLbX7oHjL9eHsA1wD3AG+PK/pzuuMZwPovjn+PKH013bEd5Po/GLT93tOdDcAHE5EFlmXQBzuPALGA6wYeg6zPp58bBC1z+ALwhXJ4DPJbu2MJYngT+EfgJsAr4NnBBuuOKi2/E9qf2OabY1DbHHuOw7U9tc8zxqX2OLb6ktT/1WB8j7v4d4Crg5PAT7/9Kd0xj9BMz+yGww8x+bmYfN7M7CHqus1GbmX3BzL4K7DGza83sSoILQsYqky7AyXH3Te6+zd0/ALSa2a+AonQHFio0s5kEw6SWAbj7BjLn27VOd/+9u38EOAf4M/B+M1uV5rhGMlr7U/tMjNpmaozU/tQ2E6f2mXy6eDHTuXs3cKeZ3Q18iODCgqzk7j8zs78BbwEmELSlH7p7tp7Tu4G3ApuArwEfAQqA9x5hPf0XQFRycC7MTLoA53kzm+7u2wDc/TYzexG4Pc1x9XuJYC7WDYMucGlIc1z99vYvuHsfwcWuaZ8jNs5o7U/t8+ipbY7dSO0vNsK2TJDJbRPUPscqaX8bdfGiiIiIiEgSZMpXBCKvaWb2f9Mdw0gU39hke3zZHn86ZXJskPnxwcgxZnr8im9sXovxqcdaJMlsiFujA9vdfV9aAwspvrHJ9PiGYmYLPbxtcKbHn8nxZXJskPnxDae/fWZ6/IpvbDI9vqHE/+1M+Bgl1tnJzP4EfMCzYI5lM5sBnO/u2ToVX8LM7FYgn2DsWBPBjWYuA/rc/TPpjA0U31hlQXxDfQtpwEPu/qYsiD9j48vk2CDz44OR2yfBjUIyNv5Mf38V39iM9rfzSOrSxYtZyt3/PpX1m1muJ+9GLzMI5u1+zSfWZP6t3hXf2GR6fK0EvUBGcPEN4XL/XKyZHn8mx5fJsUHmxwcjt8/8DI8/099fxTc2o/3tTJgS6wxlZp8nmJ7m9vCT3unufomZXQpcCVwA1AIlBNPWPAGcD7wKvN3dO8xsCbCGYGqbMuCj7v6MmRUDdwCnEbSBG939D2b2z8DbCGbDKAYuCeP4EMEV23929+vMbBbwX0AN0A583N1fMrN7CG4HXktwV8bPu/tvgFuAk8xsDfATd781de9c2mX6rd4V39hkenwvAle4e1N8oZk9HC5mevyZHF8mxwaZHx+M3D6fy/D4M/39VXxjM9rfzoRpKEiGMrPzgGvd/d0W3LUxH3gD8O/AHuD/cjCxfgWodfc1ZnYfcL+7/zxMrDe6+8fN7ELgTnc/1cy+BqwP96kAngHOJJhy7iZgnrvXm9nfEUzfc5m7t5tZVVj+N+CT7r7RzM4F/iNM+u8hSMjfS3BHxvvd/QQzeyPwOXf/h2Pw1qWdBbeuX8DBW9c/5cFdKjOC4hubTI7PzCYBB8KpPePLB76ByuT4IbPjy+TYICviG7F9ZkH8im8MMjm+RP52JlyXEuvMZGZRYANwOrAIeAH4JfBV4DPAnziYWD/s7rPD4/5/IOruN4WJ9Vfc/ZFw23aCrzUWE/RK9zeWKoL5qM8FLnL3K8P9vw285O4/iIurBKgLY+uX7+4nhYn1w+5+b7hvi7uXvt4SaxEREXl90lCQDOXuPWa2lWDYx5PAOuBigluqvjho9/i7A/YBhfFVDa6aYNzQO8O7Mg0Ie5/b4ouGOD4HaHT3M4YJPT6WTLprloiIiEhKaR7rzPY48LnweSnBnYHW+JF9zfBeADO7AGgKxw/9Bfi0mVm47cxhjv0r8FEzKwr3q3L3ZmCLmb07LDMzO32UGFqA0iOIWURERCTrKLHObEuBSQTjkPYCnWHZkWgwsyeB7wEfC8u+CkSBdWb2fLh+GHd/CLif4KKDNQRJPsAHgY+Z2VqCISpvHyWGdUCvma01s389wvglC5nZPWb2rnTWb2b/bGaTUxWDvHaZ2Wf7OxSO8vitZladzJhGeb0bzexzo+8pryVmNiP8Hy4ZRGOsX8PCMdafc/eV6Y5FXl/C8fZ/DGeFSUv9av9ytMJheLXuvj8dxx/F690ItLr7t47F60lmsOAeEX9091OP4thkTqkrcdRjLSJjZmYfNrN14bcSPwuLLzSzJ81sc3/vcjh06Jtm9ryZPWdm742r4/Nh2VozuyUsO8PMlod1LzKzyiFe+0tmtiKs8+7wNd5FcHHvvWa2xswKzewsM3vMzFaZ2V/Cq8AlQ4W9cS+Z2U/Cn/9vzKxouJ+jmX08bAdrzey3cUPY7jGz24doi280sz/Gvd53w285PgNMBh41s0fN7GMWTHlK3Ot8J1z+fRjHC2Z21Qjn8MOwfd5rZpeZ2TIz22hm54T7VYV1rQvb+7yw/EYz+5GZLQlj/0xc3deb2QYzWwzMCctmmdnquH1mm9mqJP5YJPPkDvE7ctjfRAg6G8zsa2b2GHB1muN+7XJ3PfTQQ4+jfgCnEMwSUx2uVwH3AL8m+PB+MvBKuO2dwMNABJgAbCcY7vR3BBfpFvXXET6vI5ipBuArwH+Gy/cA74rfN1z+GXB5uLyEoNcQgqFPTwI14fp7gR+l+73TY8R2NYPg4uk3hOs/Av5tuJ8jMC7u2JuAT8e1laHa4hsJevv6j/ku8M/h8ta49lwMbCKYbYnw9U8b1E4LCe4cOC7++PAcegnuGZADrArPwwiG0P0+3P8O4IZw+RKCa2kAbgxfLz+s70DYls8CngOKCOYDfoXg2xmAR4EzwuWv9b8Perz2HsP8jnxulL+Jd6Y77tf6Q7OCiMhYXQL8xsOvvT2Y6xyCpCEGrDezCeG+FwD/4+59wN6w5+Rs4CLgx+7eHldHOVDh7o+Fx/6EIEEa7GILbmRURJDUvwA8MGifOcCpwMNhbBFg99hPXVJsh7svC5d/TjCP/3A/x1PN7CaCOXJLCC7S7jdUW0yIu7eZ2SPAP5jZiwQJ9nPh5s+Y2RXh8lRgNkHyG29L//5m9gLwN3d3M3uOIDGC4PfineHrPWJm48L2D/Cgu3cBXWa2j+AD6UJgUf/vi5ndH/d6PwSuNLNrCD54nHMk5ytZZ/DvyGcIJhgY7m/ir459iK8vSqxFZKyGmpYRhp56cbgpGIerY+QXNisA7iTomd5hwVjTgmHqf8HdFxzpa0haDW4TLQz/c7wH+Ed3X2vBXWTfGLdtqLbYy6HDIYdqN/1+SJDUvwT8GIKhJMBlwAIPbqC1ZJg64l87Frce4+D/4KF+L/rPffB0qrmDtg/2W+AG4BFglbsPTvTltWWoKXVH+pvYhqSUxliLyFj9DXiPmY2DYLzoCPs+DrzXzCJmVgNcSHDnz6GmdmwimNVmYXjsh4DHBtXX/w9jvwU3L4qfKSR+mscNQI2ZLQjrj5rZKUdxrnJsTev/mQHvB5Yz/M+xFNhtwc21PphA3duAk80sP+wdvjRu2yFThLr70wQ90h8A/icsLgcawqR6LnDeUZ1h4PH+mMOEfb8HU5uOtP8VFlw7UApcHhdrJ0Fv/V2EHwLkNW3w78gT4fJQfxPlGFCPtYiMibu/YGY3A4+ZWR8w0i1qFxHc0nYtQc/K5919D/CQmZ1BMLVjN8GdRf8d+AjwvTDh3kxww6T41240sx8QjDfdCqyI23xPeGxH+JrvAm4Pk6hc4D8JviKVzPUi8BEz+z6wkWAs8l8Y+uf4ReBpgoT5OUaZOz/szbuPYBz/Rg5tt3cDfzaz3e5+cVh2H8HY5YZw/SHgk2a2juCD2/IxnOeNwI/DutoJ2v1Isa82s18BawjOd/A0rPcC7yD4wCqvbYN/R+4CKhn6b6IcA5puT0REMo6NYSqxVAhnELnV3f+W7lhGY8Gc1uXu/sV0xyLyeqMeaxERkWGYWQXBcKW1WZJULwJmEVxULCLHmHqsRURERESSQBcvioiIiIgkgRJrEREREZEkUGItIiIiIpIESqxFRERERJJAibWIiIiISBIosRYRERERSYL/B5RF6eyv01icAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a9613c470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_matrix(dataset[attributes], figsize = (12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our data the most promising correlation is between winpercent and chocolate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a ML algorithm, I need to omit non numerical data so This means removing the competitorname column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('competitorname', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "\n",
    "X = dataset[['chocolate','bar', 'peanutyalmondy', 'pricepercent', 'crispedricewafer', 'sugarpercent', 'caramel', 'nougat', 'pluribus', 'hard', 'fruity'] ]\n",
    "Y = dataset['winpercent']\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45.69303477 42.13570803 40.1282822  43.60171382 40.63395899 61.12281544\n",
      " 45.69303477 41.80062244 70.28584614 43.45801166 42.68105632 57.63143451\n",
      " 43.60171382 40.64086164 40.22063695 66.51688578 35.73901666]\n"
     ]
    }
   ],
   "source": [
    "data_predictions = ln.predict(X_validation)\n",
    "print(data_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_mse = mean_squared_error(Y_validation, data_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.901319578421734"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the Linear regression model has a 10.9 difference between estimated values and what is actually there. This is alright but lets see if we can do better with the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.185505 23.417824 46.411716 42.178772 46.116505 50.347546 39.185505\n",
      " 52.825947 66.971725 41.265511 37.722336 43.068897 42.178772 47.173229\n",
      " 46.411716 56.914547 52.825947]\n"
     ]
    }
   ],
   "source": [
    "dataset_predictions = tree_reg.predict(X_validation)\n",
    "print(dataset_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_mse = mean_squared_error(Y_validation, data_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.901319578421734"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So That's interesting, both of my values are the same. Based on that, I conclude that both the LinearRegression model and DecisionTreeRegressor are decent models but there is clearly room for improvement. Maybe if I check out other models like RandomForest Regressor I might get a smaller rmse value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_validation, Y_validation, \n",
    "                        scoring = 'neg_mean_squared_error', cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [11.37385879  7.28114866 25.23756142 25.37679794 15.82428516 14.27066227\n",
      "  9.71972123 15.907246   10.099197    7.736098  ]\n",
      "Mean: 14.28265764748347\n",
      "Standard deviation: 6.219062035862253\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [6.92042468e+00 4.85452423e+00 2.42795222e+14 2.12657807e+01\n",
      " 1.53493587e+01 1.22117807e+01 1.11684062e+01 1.07699633e+01\n",
      " 2.10024326e+01 1.76260261e+01]\n",
      "Mean: 24279522232206.14\n",
      "Standard deviation: 72838566696578.02\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, X_validation, Y_validation,\n",
    "                             scoring = \"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the RandomForest Regressor to see if it is better than Linear and Tree regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state = 42)\n",
    "forest_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.107868895006623"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_predictions = forest_reg.predict(X_validation)\n",
    "forest_mse = mean_squared_error(Y_validation, data_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the RandomForestRegressor is a little bit worse than the other two models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 9.46921733  4.83229049 18.85144562 22.33190709  8.52737099 13.38938188\n",
      "  7.26086539 11.9355089  21.8010458  13.470779  ]\n",
      "Mean: 13.186981249407822\n",
      "Standard deviation: 5.7624566534659065\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, X_validation, Y_validation, scoring = 'neg_mean_squared_error', cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000000e+01\n",
       "mean     2.427952e+13\n",
       "std      7.677859e+13\n",
       "min      4.854524e+00\n",
       "25%      1.086957e+01\n",
       "50%      1.378057e+01\n",
       "75%      2.015833e+01\n",
       "max      2.427952e+14\n",
       "dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, X_validation, Y_validation, scoring=\"neg_mean_squared_error\", cv = 10)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.018310979697173"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(X_validation, Y_validation)\n",
    "data_predictions = svm_reg.predict(X_validation)\n",
    "svm_mse = mean_squared_error(Y_validation, data_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (34) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (23) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=30, n_jobs=1, oob_score=False, random_state=42,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.987762323911214 {'max_features': 2, 'n_estimators': 3}\n",
      "11.996343697963193 {'max_features': 2, 'n_estimators': 10}\n",
      "11.267454281541877 {'max_features': 2, 'n_estimators': 30}\n",
      "12.066334823521995 {'max_features': 4, 'n_estimators': 3}\n",
      "11.649167451789067 {'max_features': 4, 'n_estimators': 10}\n",
      "11.380670436901045 {'max_features': 4, 'n_estimators': 30}\n",
      "13.859715789344328 {'max_features': 6, 'n_estimators': 3}\n",
      "12.007168592851999 {'max_features': 6, 'n_estimators': 10}\n",
      "11.29715819128242 {'max_features': 6, 'n_estimators': 30}\n",
      "12.683837389225 {'max_features': 8, 'n_estimators': 3}\n",
      "11.23495026154335 {'max_features': 8, 'n_estimators': 10}\n",
      "10.964701401141692 {'max_features': 8, 'n_estimators': 30}\n",
      "12.649745646772503 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "12.650042471058862 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "12.05700638874808 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "11.469164030477753 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "11.942552702229635 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "11.940897644379481 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/owner/miniconda3/envs/nnseries/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-168.681970</td>\n",
       "      <td>-76.477072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 3}</td>\n",
       "      <td>17</td>\n",
       "      <td>-19.325716</td>\n",
       "      <td>...</td>\n",
       "      <td>-130.235501</td>\n",
       "      <td>-90.710314</td>\n",
       "      <td>-73.055369</td>\n",
       "      <td>-107.412952</td>\n",
       "      <td>-388.177552</td>\n",
       "      <td>-87.747086</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>131.670028</td>\n",
       "      <td>26.259253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-143.912262</td>\n",
       "      <td>-45.593414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 10}</td>\n",
       "      <td>10</td>\n",
       "      <td>-15.946010</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.667958</td>\n",
       "      <td>-52.928586</td>\n",
       "      <td>-127.776832</td>\n",
       "      <td>-49.438882</td>\n",
       "      <td>-346.827858</td>\n",
       "      <td>-46.072892</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>114.576716</td>\n",
       "      <td>5.680859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>-126.955526</td>\n",
       "      <td>-29.645869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 30}</td>\n",
       "      <td>3</td>\n",
       "      <td>-17.737776</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.866777</td>\n",
       "      <td>-32.269930</td>\n",
       "      <td>-151.792338</td>\n",
       "      <td>-29.607755</td>\n",
       "      <td>-213.002746</td>\n",
       "      <td>-26.531466</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>76.326279</td>\n",
       "      <td>6.589420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>-145.596436</td>\n",
       "      <td>-75.203407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 3}</td>\n",
       "      <td>13</td>\n",
       "      <td>-23.067540</td>\n",
       "      <td>...</td>\n",
       "      <td>-190.717225</td>\n",
       "      <td>-129.526761</td>\n",
       "      <td>-80.858751</td>\n",
       "      <td>-71.682249</td>\n",
       "      <td>-192.910771</td>\n",
       "      <td>-70.695253</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>86.387229</td>\n",
       "      <td>30.617699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>-135.703102</td>\n",
       "      <td>-41.766531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 10}</td>\n",
       "      <td>7</td>\n",
       "      <td>-34.075922</td>\n",
       "      <td>...</td>\n",
       "      <td>-70.320464</td>\n",
       "      <td>-45.428018</td>\n",
       "      <td>-93.247414</td>\n",
       "      <td>-45.694328</td>\n",
       "      <td>-275.169900</td>\n",
       "      <td>-47.512326</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>91.450628</td>\n",
       "      <td>7.941001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028328</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>-129.519660</td>\n",
       "      <td>-29.330353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 30}</td>\n",
       "      <td>5</td>\n",
       "      <td>-34.221930</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.228183</td>\n",
       "      <td>-30.582150</td>\n",
       "      <td>-158.455089</td>\n",
       "      <td>-30.621485</td>\n",
       "      <td>-179.168592</td>\n",
       "      <td>-27.938991</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>71.273899</td>\n",
       "      <td>6.493375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-192.091722</td>\n",
       "      <td>-71.632238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 3}</td>\n",
       "      <td>18</td>\n",
       "      <td>-51.411077</td>\n",
       "      <td>...</td>\n",
       "      <td>-190.717225</td>\n",
       "      <td>-108.860664</td>\n",
       "      <td>-117.124917</td>\n",
       "      <td>-71.859345</td>\n",
       "      <td>-231.634418</td>\n",
       "      <td>-78.793000</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>112.195437</td>\n",
       "      <td>24.508836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-144.172098</td>\n",
       "      <td>-42.178298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 10}</td>\n",
       "      <td>11</td>\n",
       "      <td>-30.025507</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.167088</td>\n",
       "      <td>-49.916340</td>\n",
       "      <td>-140.098876</td>\n",
       "      <td>-51.098442</td>\n",
       "      <td>-276.209517</td>\n",
       "      <td>-39.403243</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>96.769456</td>\n",
       "      <td>8.395284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>-127.625783</td>\n",
       "      <td>-30.114025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 30}</td>\n",
       "      <td>4</td>\n",
       "      <td>-37.608637</td>\n",
       "      <td>...</td>\n",
       "      <td>-67.133824</td>\n",
       "      <td>-32.061628</td>\n",
       "      <td>-133.902654</td>\n",
       "      <td>-31.977057</td>\n",
       "      <td>-189.006558</td>\n",
       "      <td>-26.513125</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>70.070906</td>\n",
       "      <td>6.935517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>-160.879731</td>\n",
       "      <td>-71.762275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 3}</td>\n",
       "      <td>16</td>\n",
       "      <td>-23.076484</td>\n",
       "      <td>...</td>\n",
       "      <td>-150.443125</td>\n",
       "      <td>-105.366804</td>\n",
       "      <td>-92.324612</td>\n",
       "      <td>-94.080787</td>\n",
       "      <td>-211.203501</td>\n",
       "      <td>-63.123102</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>108.327905</td>\n",
       "      <td>25.738201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>-126.224107</td>\n",
       "      <td>-40.837181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>-25.918233</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.181396</td>\n",
       "      <td>-47.992944</td>\n",
       "      <td>-126.558580</td>\n",
       "      <td>-48.258084</td>\n",
       "      <td>-235.871091</td>\n",
       "      <td>-39.588782</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>84.607278</td>\n",
       "      <td>7.355340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>-120.224677</td>\n",
       "      <td>-29.459880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 30}</td>\n",
       "      <td>1</td>\n",
       "      <td>-33.426104</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.815454</td>\n",
       "      <td>-32.007917</td>\n",
       "      <td>-139.526090</td>\n",
       "      <td>-30.776074</td>\n",
       "      <td>-174.718801</td>\n",
       "      <td>-27.474058</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>69.281182</td>\n",
       "      <td>7.450127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>-160.016065</td>\n",
       "      <td>-1.554144</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>14</td>\n",
       "      <td>-33.876731</td>\n",
       "      <td>...</td>\n",
       "      <td>-205.108742</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>-159.888186</td>\n",
       "      <td>-1.397076</td>\n",
       "      <td>-215.691844</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>72.480950</td>\n",
       "      <td>0.954565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010314</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>-160.023575</td>\n",
       "      <td>-1.554144</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>15</td>\n",
       "      <td>-68.350787</td>\n",
       "      <td>...</td>\n",
       "      <td>-198.210237</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>-138.260988</td>\n",
       "      <td>-1.397076</td>\n",
       "      <td>-255.693533</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>62.825854</td>\n",
       "      <td>0.954565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>-145.371403</td>\n",
       "      <td>-1.554144</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>12</td>\n",
       "      <td>-37.678467</td>\n",
       "      <td>...</td>\n",
       "      <td>-192.909261</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>-109.592411</td>\n",
       "      <td>-1.397076</td>\n",
       "      <td>-237.333977</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>71.108391</td>\n",
       "      <td>0.954565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-131.541724</td>\n",
       "      <td>-1.554144</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>6</td>\n",
       "      <td>-30.918959</td>\n",
       "      <td>...</td>\n",
       "      <td>-154.160000</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>-132.250281</td>\n",
       "      <td>-1.397076</td>\n",
       "      <td>-210.580631</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>60.901304</td>\n",
       "      <td>0.954565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-142.624565</td>\n",
       "      <td>-1.554144</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>9</td>\n",
       "      <td>-96.019779</td>\n",
       "      <td>...</td>\n",
       "      <td>-164.834642</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>-177.892094</td>\n",
       "      <td>-1.397076</td>\n",
       "      <td>-99.270070</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>38.137296</td>\n",
       "      <td>0.954565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-142.585037</td>\n",
       "      <td>-1.554144</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>8</td>\n",
       "      <td>-69.092395</td>\n",
       "      <td>...</td>\n",
       "      <td>-151.171606</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>-147.297631</td>\n",
       "      <td>-1.397076</td>\n",
       "      <td>-203.654139</td>\n",
       "      <td>-2.560411</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>44.941977</td>\n",
       "      <td>0.954565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.004724         0.000844      -168.681970        -76.477072   \n",
       "1        0.012911         0.001325      -143.912262        -45.593414   \n",
       "2        0.029653         0.001887      -126.955526        -29.645869   \n",
       "3        0.003750         0.000572      -145.596436        -75.203407   \n",
       "4        0.010328         0.000946      -135.703102        -41.766531   \n",
       "5        0.028328         0.001857      -129.519660        -29.330353   \n",
       "6        0.003806         0.000586      -192.091722        -71.632238   \n",
       "7        0.010821         0.000993      -144.172098        -42.178298   \n",
       "8        0.028369         0.001819      -127.625783        -30.114025   \n",
       "9        0.003713         0.000567      -160.879731        -71.762275   \n",
       "10       0.010157         0.000911      -126.224107        -40.837181   \n",
       "11       0.028686         0.001956      -120.224677        -29.459880   \n",
       "12       0.003746         0.000713      -160.016065         -1.554144   \n",
       "13       0.010314         0.000992      -160.023575         -1.554144   \n",
       "14       0.003679         0.000578      -145.371403         -1.554144   \n",
       "15       0.009777         0.000906      -131.541724         -1.554144   \n",
       "16       0.003695         0.000638      -142.624565         -1.554144   \n",
       "17       0.010555         0.001013      -142.585037         -1.554144   \n",
       "\n",
       "   param_bootstrap param_max_features param_n_estimators  \\\n",
       "0              NaN                  2                  3   \n",
       "1              NaN                  2                 10   \n",
       "2              NaN                  2                 30   \n",
       "3              NaN                  4                  3   \n",
       "4              NaN                  4                 10   \n",
       "5              NaN                  4                 30   \n",
       "6              NaN                  6                  3   \n",
       "7              NaN                  6                 10   \n",
       "8              NaN                  6                 30   \n",
       "9              NaN                  8                  3   \n",
       "10             NaN                  8                 10   \n",
       "11             NaN                  8                 30   \n",
       "12           False                  2                  3   \n",
       "13           False                  2                 10   \n",
       "14           False                  3                  3   \n",
       "15           False                  3                 10   \n",
       "16           False                  4                  3   \n",
       "17           False                  4                 10   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "0              {'max_features': 2, 'n_estimators': 3}               17   \n",
       "1             {'max_features': 2, 'n_estimators': 10}               10   \n",
       "2             {'max_features': 2, 'n_estimators': 30}                3   \n",
       "3              {'max_features': 4, 'n_estimators': 3}               13   \n",
       "4             {'max_features': 4, 'n_estimators': 10}                7   \n",
       "5             {'max_features': 4, 'n_estimators': 30}                5   \n",
       "6              {'max_features': 6, 'n_estimators': 3}               18   \n",
       "7             {'max_features': 6, 'n_estimators': 10}               11   \n",
       "8             {'max_features': 6, 'n_estimators': 30}                4   \n",
       "9              {'max_features': 8, 'n_estimators': 3}               16   \n",
       "10            {'max_features': 8, 'n_estimators': 10}                2   \n",
       "11            {'max_features': 8, 'n_estimators': 30}                1   \n",
       "12  {'bootstrap': False, 'max_features': 2, 'n_est...               14   \n",
       "13  {'bootstrap': False, 'max_features': 2, 'n_est...               15   \n",
       "14  {'bootstrap': False, 'max_features': 3, 'n_est...               12   \n",
       "15  {'bootstrap': False, 'max_features': 3, 'n_est...                6   \n",
       "16  {'bootstrap': False, 'max_features': 4, 'n_est...                9   \n",
       "17  {'bootstrap': False, 'max_features': 4, 'n_est...                8   \n",
       "\n",
       "    split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0          -19.325716       ...               -130.235501          -90.710314   \n",
       "1          -15.946010       ...                -57.667958          -52.928586   \n",
       "2          -17.737776       ...                -71.866777          -32.269930   \n",
       "3          -23.067540       ...               -190.717225         -129.526761   \n",
       "4          -34.075922       ...                -70.320464          -45.428018   \n",
       "5          -34.221930       ...                -66.228183          -30.582150   \n",
       "6          -51.411077       ...               -190.717225         -108.860664   \n",
       "7          -30.025507       ...                -53.167088          -49.916340   \n",
       "8          -37.608637       ...                -67.133824          -32.061628   \n",
       "9          -23.076484       ...               -150.443125         -105.366804   \n",
       "10         -25.918233       ...                -44.181396          -47.992944   \n",
       "11         -33.426104       ...                -51.815454          -32.007917   \n",
       "12         -33.876731       ...               -205.108742           -2.560411   \n",
       "13         -68.350787       ...               -198.210237           -2.560411   \n",
       "14         -37.678467       ...               -192.909261           -2.560411   \n",
       "15         -30.918959       ...               -154.160000           -2.560411   \n",
       "16         -96.019779       ...               -164.834642           -2.560411   \n",
       "17         -69.092395       ...               -151.171606           -2.560411   \n",
       "\n",
       "    split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0          -73.055369         -107.412952        -388.177552   \n",
       "1         -127.776832          -49.438882        -346.827858   \n",
       "2         -151.792338          -29.607755        -213.002746   \n",
       "3          -80.858751          -71.682249        -192.910771   \n",
       "4          -93.247414          -45.694328        -275.169900   \n",
       "5         -158.455089          -30.621485        -179.168592   \n",
       "6         -117.124917          -71.859345        -231.634418   \n",
       "7         -140.098876          -51.098442        -276.209517   \n",
       "8         -133.902654          -31.977057        -189.006558   \n",
       "9          -92.324612          -94.080787        -211.203501   \n",
       "10        -126.558580          -48.258084        -235.871091   \n",
       "11        -139.526090          -30.776074        -174.718801   \n",
       "12        -159.888186           -1.397076        -215.691844   \n",
       "13        -138.260988           -1.397076        -255.693533   \n",
       "14        -109.592411           -1.397076        -237.333977   \n",
       "15        -132.250281           -1.397076        -210.580631   \n",
       "16        -177.892094           -1.397076         -99.270070   \n",
       "17        -147.297631           -1.397076        -203.654139   \n",
       "\n",
       "    split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0           -87.747086      0.000300        0.000133      131.670028   \n",
       "1           -46.072892      0.001758        0.000215      114.576716   \n",
       "2           -26.531466      0.000999        0.000057       76.326279   \n",
       "3           -70.695253      0.000059        0.000008       86.387229   \n",
       "4           -47.512326      0.000181        0.000048       91.450628   \n",
       "5           -27.938991      0.000244        0.000047       71.273899   \n",
       "6           -78.793000      0.000132        0.000017      112.195437   \n",
       "7           -39.403243      0.000604        0.000044       96.769456   \n",
       "8           -26.513125      0.000250        0.000030       70.070906   \n",
       "9           -63.123102      0.000022        0.000005      108.327905   \n",
       "10          -39.588782      0.000076        0.000015       84.607278   \n",
       "11          -27.474058      0.000569        0.000238       69.281182   \n",
       "12           -2.560411      0.000160        0.000153       72.480950   \n",
       "13           -2.560411      0.000362        0.000065       62.825854   \n",
       "14           -2.560411      0.000107        0.000011       71.108391   \n",
       "15           -2.560411      0.000066        0.000012       60.901304   \n",
       "16           -2.560411      0.000067        0.000054       38.137296   \n",
       "17           -2.560411      0.000199        0.000037       44.941977   \n",
       "\n",
       "    std_train_score  \n",
       "0         26.259253  \n",
       "1          5.680859  \n",
       "2          6.589420  \n",
       "3         30.617699  \n",
       "4          7.941001  \n",
       "5          6.493375  \n",
       "6         24.508836  \n",
       "7          8.395284  \n",
       "8          6.935517  \n",
       "9         25.738201  \n",
       "10         7.355340  \n",
       "11         7.450127  \n",
       "12         0.954565  \n",
       "13         0.954565  \n",
       "14         0.954565  \n",
       "15         0.954565  \n",
       "16         0.954565  \n",
       "17         0.954565  \n",
       "\n",
       "[18 rows x 23 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0a97445518>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0a97445278>},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.151164343138566 {'max_features': 7, 'n_estimators': 180}\n",
      "11.3080223351143 {'max_features': 5, 'n_estimators': 15}\n",
      "11.831692047341036 {'max_features': 3, 'n_estimators': 72}\n",
      "11.218961774079403 {'max_features': 5, 'n_estimators': 21}\n",
      "11.177195533444383 {'max_features': 7, 'n_estimators': 122}\n",
      "11.852418211881057 {'max_features': 3, 'n_estimators': 75}\n",
      "11.722569771336625 {'max_features': 3, 'n_estimators': 88}\n",
      "11.328062710073551 {'max_features': 5, 'n_estimators': 100}\n",
      "11.569629347322198 {'max_features': 3, 'n_estimators': 150}\n",
      "13.926475362090542 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Manager,\n",
    "\n",
    "Based on our results we have determined that the idea of looking at what makes certain candy better than others requires some more time, effort, and data. We need more features to improve the accuracy of the training models. We have found that the Linear and Tree regressors are better than the Random forest regressor based on the difference between estimated win percent and actual win percent. I assure you once I recieve more data, the estimations will be more close to what is real and we can hopefully move on to testing new candy with our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project has thrown me into the pool of machine learning and data science very deep and although I have learned way more than I could have imagined, my results are not enough to say that I'm done. I need more data, mainly features. The more features I have I think the better my models will run. It means there is more information available to map out and correlate. As of now the chocolate feature is the only feature that strongly correlates to win percent, so maybe take a look at other types of ingrediants that may influence the winpercent. My Linear and Tree Regressor models have high hopes for the future since they yeilded the least error, but the RandomForest Regressor wasn't off by too much either so maybe I can fine tune that at a later time. I am not entirely satisfied with my system. I want at most a 5 points difference between estimated and actual. That means my models need to improve by atleast 50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
